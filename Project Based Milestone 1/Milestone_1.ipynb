{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEPyM7LIrCsH"
      },
      "source": [
        "# Tutorial Pemodelan Data dan ETL dengan DuckDB\n",
        "\n",
        "## Pengantar\n",
        "\n",
        "Dalam tutorial ini, kita akan mempelajari cara implementasi pipeline ETL (Extract, Transform, Load) untuk data warehouse menggunakan DuckDB. Kita akan fokus pada pemodelan dimensi dan proses ETL yang realistis."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GIT"
      ],
      "metadata": {
        "id": "4KAUvssCugDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# 1. Masukkan informasi GitHub\n",
        "github_username = \"your_github_username\"  # Ganti dengan username GitHub-mu\n",
        "github_token = getpass(\"Enter your GitHub Token: \")\n",
        "\n",
        "# 2. Konfigurasi Git\n",
        "os.system(\"git config --global user.name 'your_github_username'\")  # Ganti dengan username GitHub-mu\n",
        "os.system(\"git config --global user.email 'your_email@example.com'\")  # Ganti dengan email GitHub-mu\n",
        "\n",
        "# 3. URL repository GitHub (Ganti dengan repo yang ingin di-clone)\n",
        "repo_url = f\"https://{github_username}:{github_token}@github.com/your_github_username/your_repository.git\"\n",
        "\n",
        "# 4. Clone repository (ganti nama repo)\n",
        "os.system(f\"git clone {repo_url}\")"
      ],
      "metadata": {
        "id": "PT-0yHBdufg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jih58T9zqysp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "makan malam"
      ],
      "metadata": {
        "id": "vdRu2F1gvBeR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cey-SOtIrCsM"
      },
      "source": [
        "## 1. Instalasi dan Persiapan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63pVp3PprCsN"
      },
      "source": [
        "Instal library yang diperlukan<br>\n",
        "pip install duckdb pandas numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKpZsz5arCsN"
      },
      "source": [
        "Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfnhQnvbrCsO"
      },
      "outputs": [],
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gKdfv5orCsP"
      },
      "source": [
        "Koneksi ke DuckDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6TyFCERrCsQ"
      },
      "outputs": [],
      "source": [
        "conn = duckdb.connect('retail_dw.db')\n",
        "print(\"Terhubung ke DuckDB!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHFdy0Z-rCsQ"
      },
      "source": [
        "## 2. Konsep Dasar Pemodelan Data Warehouse\n",
        "\n",
        "### OLTP vs OLAP\n",
        "\n",
        "| Aspek | OLTP | OLAP |\n",
        "|--------|------|------|\n",
        "| Tujuan | Pemrosesan transaksi | Analisis data |\n",
        "| Desain | Ternormalisasi | Denormalisasi |\n",
        "| Kueri | Sederhana, fokus pada catatan spesifik | Kompleks, melibatkan agregasi dan join |\n",
        "| Performa | Dioptimalkan untuk transaksi (tulis) | Dioptimalkan untuk query (baca) |\n",
        "| Data | Data saat ini | Data historis |\n",
        "| Ukuran | Lebih kecil | Jauh lebih besar |\n",
        "\n",
        "### Skema Pemodelan Dimensional\n",
        "\n",
        "**1. Star Schema (Skema Bintang)**\n",
        "- Tabel fakta pusat dengan pengukuran bisnis\n",
        "- Tabel dimensi terhubung langsung ke tabel fakta\n",
        "\n",
        "**2. Snowflake Schema (Skema Kepingan Salju)**\n",
        "- Perluasan dari skema bintang\n",
        "- Dimensi-dimensi dinormalisasi lebih lanjut\n",
        "\n",
        "**3. Fact Constellation (Konstelasi Fakta)**\n",
        "- Beberapa tabel fakta berbagi tabel dimensi\n",
        "- Juga dikenal sebagai Galaxy Schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtQXVELLrCsR"
      },
      "source": [
        "## 3. Persiapan Data Sumber<br>\n",
        "<br>\n",
        "Dalam situasi dunia nyata, data berasal dari berbagai sumber. Mari simulasikan dengan beberapa dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY6d5nVKrCsR"
      },
      "source": [
        "Fungsi untuk mengunduh dataset contoh (lebih realistis dibanding data random)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpOF_Y6wrCsR"
      },
      "outputs": [],
      "source": [
        "def download_sample_data():\n",
        "    \"\"\"Mengunduh dan menyiapkan dataset sampel\"\"\"\n",
        "\n",
        "    # Buat folder data jika belum ada\n",
        "    if not os.path.exists('data'):\n",
        "        os.makedirs('data')\n",
        "\n",
        "    # Data transaksi penjualan (simulasi dari CSV ekspor)\n",
        "    # Membuat data contoh yang realistis\n",
        "\n",
        "    # 1. Data produk\n",
        "    products = pd.DataFrame({\n",
        "        'product_id': range(1, 51),\n",
        "        'name': [f'Product-{i}' for i in range(1, 51)],\n",
        "        'category': np.random.choice(['Electronics', 'Clothing', 'Home', 'Books', 'Food'], 50),\n",
        "        'subcategory': np.random.choice(['Smartphones', 'Laptops', 'T-shirts', 'Pants', 'Kitchen',\n",
        "                                       'Bedroom', 'Fiction', 'Non-fiction', 'Snacks', 'Beverages'], 50),\n",
        "        'base_cost': np.random.uniform(5, 200, 50).round(2),\n",
        "        'base_price': np.random.uniform(10, 300, 50).round(2)\n",
        "    })\n",
        "\n",
        "    # 2. Data toko\n",
        "    stores = pd.DataFrame({\n",
        "        'store_id': range(1, 21),\n",
        "        'name': [f'Store-{i}' for i in range(1, 21)],\n",
        "        'city': np.random.choice(['Jakarta', 'Bandung', 'Surabaya', 'Yogyakarta', 'Medan'], 20),\n",
        "        'region': np.random.choice(['Jawa', 'Sumatera', 'Kalimantan', 'Sulawesi'], 20),\n",
        "        'type': np.random.choice(['Mall', 'Street', 'Standalone'], 20)\n",
        "    })\n",
        "\n",
        "    # 3. Data pelanggan\n",
        "    customers = pd.DataFrame({\n",
        "        'customer_id': range(1, 201),\n",
        "        'first_name': [f'First-{i}' for i in range(1, 201)],\n",
        "        'last_name': [f'Last-{i}' for i in range(1, 201)],\n",
        "        'email': [f'customer{i}@example.com' for i in range(1, 201)],\n",
        "        'city': np.random.choice(['Jakarta', 'Bandung', 'Surabaya', 'Yogyakarta', 'Medan',\n",
        "                                 'Makassar', 'Palembang', 'Semarang'], 200),\n",
        "        'membership': np.random.choice(['Silver', 'Gold', 'Platinum', 'Regular'], 200)\n",
        "    })\n",
        "\n",
        "    # 4. Generate transaksi\n",
        "    # Simulasi data dari point of sale system\n",
        "    num_transactions = 5000\n",
        "    transactions = []\n",
        "\n",
        "    start_date = datetime(2022, 1, 1)\n",
        "    end_date = datetime(2023, 12, 31)\n",
        "    dates = [start_date + timedelta(days=np.random.randint(0, (end_date-start_date).days))\n",
        "             for _ in range(num_transactions)]\n",
        "\n",
        "    for i in range(num_transactions):\n",
        "        tx_date = dates[i]\n",
        "        store_id = np.random.choice(stores['store_id'])\n",
        "        customer_id = np.random.choice(customers['customer_id'])\n",
        "\n",
        "        # Setiap transaksi bisa punya beberapa item\n",
        "        items_count = np.random.randint(1, 5)\n",
        "\n",
        "        for j in range(items_count):\n",
        "            product_id = np.random.choice(products['product_id'])\n",
        "            product_info = products[products['product_id'] == product_id].iloc[0]\n",
        "\n",
        "            # Harga bisa bervariasi dari waktu ke waktu\n",
        "            price_variance = np.random.uniform(0.9, 1.1)\n",
        "            price = round(product_info['base_price'] * price_variance, 2)\n",
        "\n",
        "            cost_variance = np.random.uniform(0.95, 1.05)\n",
        "            cost = round(product_info['base_cost'] * cost_variance, 2)\n",
        "\n",
        "            quantity = np.random.randint(1, 6)\n",
        "\n",
        "            # Diskon kadang diberikan\n",
        "            discount_pct = 0\n",
        "            if np.random.random() < 0.3:  # 30% transaksi mendapat diskon\n",
        "                discount_pct = np.random.choice([5, 10, 15, 20, 25, 50]) / 100\n",
        "\n",
        "            discount_amount = round(price * quantity * discount_pct, 2)\n",
        "            total = round(price * quantity - discount_amount, 2)\n",
        "            profit = round(total - (cost * quantity), 2)\n",
        "\n",
        "            transactions.append({\n",
        "                'transaction_id': f'TX-{i+1}',\n",
        "                'date': tx_date.strftime('%Y-%m-%d'),\n",
        "                'store_id': store_id,\n",
        "                'customer_id': customer_id,\n",
        "                'product_id': product_id,\n",
        "                'quantity': quantity,\n",
        "                'unit_price': price,\n",
        "                'unit_cost': cost,\n",
        "                'discount_pct': discount_pct,\n",
        "                'discount_amount': discount_amount,\n",
        "                'total_amount': total,\n",
        "                'profit': profit\n",
        "            })\n",
        "\n",
        "    # Simpan semua data ke CSV (simulasi data dari berbagai sumber)\n",
        "    products.to_csv('data/products.csv', index=False)\n",
        "    stores.to_csv('data/stores.csv', index=False)\n",
        "    customers.to_csv('data/customers.csv', index=False)\n",
        "\n",
        "    tx_df = pd.DataFrame(transactions)\n",
        "    tx_df.to_csv('data/transactions.csv', index=False)\n",
        "\n",
        "    # Buat data yang \"kotor\" dengan sengaja (seperti di dunia nyata)\n",
        "    # Salin data pelanggan, tapi dengan beberapa kesalahan\n",
        "    customers_dirty = customers.copy()\n",
        "    # Ubah beberapa nilai\n",
        "    for i in range(20):\n",
        "        idx = np.random.randint(0, len(customers_dirty))\n",
        "        if np.random.random() < 0.5:\n",
        "            customers_dirty.loc[idx, 'city'] = customers_dirty.loc[idx, 'city'].upper()\n",
        "        else:\n",
        "            customers_dirty.loc[idx, 'city'] = customers_dirty.loc[idx, 'city'].lower()\n",
        "\n",
        "    # Tambahkan beberapa nilai duplikat dengan ID berbeda\n",
        "    duplicates = customers.sample(10).copy()\n",
        "    duplicates['customer_id'] = range(201, 211)\n",
        "    customers_dirty = pd.concat([customers_dirty, duplicates])\n",
        "\n",
        "    # Tambahkan nilai kosong\n",
        "    for i in range(15):\n",
        "        idx = np.random.randint(0, len(customers_dirty))\n",
        "        col = np.random.choice(['first_name', 'last_name', 'email', 'city'])\n",
        "        customers_dirty.loc[idx, col] = np.nan\n",
        "\n",
        "    customers_dirty.to_csv('data/customers_dirty.csv', index=False)\n",
        "\n",
        "    print(f\"Data sampel berhasil dibuat:\")\n",
        "    print(f\"- {len(products)} produk\")\n",
        "    print(f\"- {len(stores)} toko\")\n",
        "    print(f\"- {len(customers)} pelanggan\")\n",
        "    print(f\"- {len(tx_df)} transaksi\")\n",
        "    print(f\"- {len(customers_dirty)} pelanggan (dengan data kotor)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFB6v9kErCsS"
      },
      "source": [
        "Unduh/Buat data sampel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AWn_ifxrCsS"
      },
      "outputs": [],
      "source": [
        "download_sample_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad4Bx0uMrCsS"
      },
      "source": [
        "## 4. Perancangan Model Data Warehouse<br>\n",
        "<br>\n",
        "Kita akan menerapkan model Star Schema untuk data warehouse retail kita:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I55yHwirrCsT"
      },
      "outputs": [],
      "source": [
        "def create_data_warehouse_schema():\n",
        "    \"\"\"Membuat skema data warehouse (dimensi & tabel fakta)\"\"\"\n",
        "\n",
        "    # Drop dependent tables first to avoid dependency errors\n",
        "    try:\n",
        "        conn.execute(\"DROP TABLE IF EXISTS fact_sales;\")\n",
        "        conn.execute(\"DROP TABLE IF EXISTS fact_inventory;\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # 1. Buat dimensi tanggal terlebih dahulu - fixed for DuckDB\n",
        "    conn.execute(\"\"\"\n",
        "    -- Dimensi Tanggal\n",
        "    CREATE OR REPLACE TABLE dim_date AS\n",
        "    WITH date_range AS (\n",
        "      SELECT unnest(generate_series('2022-01-01'::DATE, '2023-12-31'::DATE, INTERVAL '1 day')) as date\n",
        "    )\n",
        "    SELECT\n",
        "      (EXTRACT(YEAR FROM date) * 10000 + EXTRACT(MONTH FROM date) * 100 + EXTRACT(DAY FROM date))::INTEGER AS date_key,\n",
        "      date,\n",
        "      EXTRACT(DAY FROM date) AS day,\n",
        "      EXTRACT(MONTH FROM date) AS month,\n",
        "      strftime(date, '%B') AS month_name,\n",
        "      EXTRACT(QUARTER FROM date) AS quarter,\n",
        "      EXTRACT(YEAR FROM date) AS year,\n",
        "      EXTRACT(DOW FROM date) AS day_of_week,\n",
        "      strftime(date, '%A') AS day_name,\n",
        "      CASE\n",
        "        WHEN EXTRACT(MONTH FROM date) BETWEEN 3 AND 5 THEN 'Spring'\n",
        "        WHEN EXTRACT(MONTH FROM date) BETWEEN 6 AND 8 THEN 'Summer'\n",
        "        WHEN EXTRACT(MONTH FROM date) BETWEEN 9 AND 11 THEN 'Fall'\n",
        "        ELSE 'Winter'\n",
        "      END AS season\n",
        "    FROM date_range;\n",
        "    \"\"\")\n",
        "\n",
        "    # Add primary key to dim_date table\n",
        "    conn.execute(\"\"\"\n",
        "    ALTER TABLE dim_date ADD PRIMARY KEY (date_key);\n",
        "    \"\"\")\n",
        "\n",
        "    # 2. Buat tabel dimensi lainnya (kosong)\n",
        "    conn.execute(\"\"\"\n",
        "    -- Dimensi Produk\n",
        "    CREATE OR REPLACE TABLE dim_product (\n",
        "      product_key INTEGER PRIMARY KEY,\n",
        "      product_id INTEGER NOT NULL,\n",
        "      product_name VARCHAR,\n",
        "      category VARCHAR,\n",
        "      subcategory VARCHAR,\n",
        "      unit_cost DECIMAL(10,2),\n",
        "      unit_price DECIMAL(10,2),\n",
        "      effective_date DATE,\n",
        "      expiration_date DATE,\n",
        "      current_flag BOOLEAN\n",
        "    );\n",
        "\n",
        "    -- Dimensi Toko\n",
        "    CREATE OR REPLACE TABLE dim_store (\n",
        "      store_key INTEGER PRIMARY KEY,\n",
        "      store_id INTEGER NOT NULL,\n",
        "      store_name VARCHAR,\n",
        "      city VARCHAR,\n",
        "      region VARCHAR,\n",
        "      store_type VARCHAR,\n",
        "      effective_date DATE,\n",
        "      expiration_date DATE,\n",
        "      current_flag BOOLEAN\n",
        "    );\n",
        "\n",
        "    -- Dimensi Pelanggan\n",
        "    CREATE OR REPLACE TABLE dim_customer (\n",
        "      customer_key INTEGER PRIMARY KEY,\n",
        "      customer_id INTEGER NOT NULL,\n",
        "      first_name VARCHAR,\n",
        "      last_name VARCHAR,\n",
        "      email VARCHAR,\n",
        "      city VARCHAR,\n",
        "      membership VARCHAR,\n",
        "      effective_date DATE,\n",
        "      expiration_date DATE,\n",
        "      current_flag BOOLEAN\n",
        "    );\n",
        "\n",
        "    -- Tabel Fakta Penjualan\n",
        "    CREATE OR REPLACE TABLE fact_sales (\n",
        "      sales_key INTEGER PRIMARY KEY,\n",
        "      transaction_id VARCHAR,\n",
        "      date_key INTEGER,\n",
        "      product_key INTEGER,\n",
        "      store_key INTEGER,\n",
        "      customer_key INTEGER,\n",
        "      quantity INTEGER,\n",
        "      unit_price DECIMAL(10,2),\n",
        "      unit_cost DECIMAL(10,2),\n",
        "      discount_pct DECIMAL(5,2),\n",
        "      discount_amount DECIMAL(10,2),\n",
        "      sales_amount DECIMAL(10,2),\n",
        "      profit_amount DECIMAL(10,2),\n",
        "\n",
        "      FOREIGN KEY (date_key) REFERENCES dim_date(date_key),\n",
        "      FOREIGN KEY (product_key) REFERENCES dim_product(product_key),\n",
        "      FOREIGN KEY (store_key) REFERENCES dim_store(store_key),\n",
        "      FOREIGN KEY (customer_key) REFERENCES dim_customer(customer_key)\n",
        "    );\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"Skema data warehouse berhasil dibuat!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-fmyTgXrCsT"
      },
      "source": [
        "Buat skema data warehouse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKj_6Hi6rCsT"
      },
      "outputs": [],
      "source": [
        "create_data_warehouse_schema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg79lAw4rCsT"
      },
      "source": [
        "## 5. Proses ETL (Extract, Transform, Load)<br>\n",
        "<br>\n",
        "Sekarang kita implementasikan proses ETL yang komprehensif:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF9qTfLPrCsT"
      },
      "source": [
        "### 5.1 Extract - Mengambil Data dari Sumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xgyWX1irCsU"
      },
      "outputs": [],
      "source": [
        "def extract_source_data():\n",
        "    \"\"\"Ekstrak data dari berbagai sumber\"\"\"\n",
        "\n",
        "    # Baca data dari file CSV\n",
        "    products_df = pd.read_csv('data/products.csv')\n",
        "    stores_df = pd.read_csv('data/stores.csv')\n",
        "    customers_df = pd.read_csv('data/customers_dirty.csv')  # Sengaja menggunakan data kotor\n",
        "    transactions_df = pd.read_csv('data/transactions.csv')\n",
        "\n",
        "    print(f\"Data berhasil diekstrak:\")\n",
        "    print(f\"- Produk: {len(products_df)} baris\")\n",
        "    print(f\"- Toko: {len(stores_df)} baris\")\n",
        "    print(f\"- Pelanggan: {len(customers_df)} baris\")\n",
        "    print(f\"- Transaksi: {len(transactions_df)} baris\")\n",
        "\n",
        "    return products_df, stores_df, customers_df, transactions_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1fo4GpWrCsU"
      },
      "source": [
        "Ekstrak data dari sumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZn__EqIrCsU"
      },
      "outputs": [],
      "source": [
        "products_df, stores_df, customers_df, transactions_df = extract_source_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPS3vMtHrCsU"
      },
      "source": [
        "### 5.2 Transform - Membersihkan dan Mengubah Data<br>\n",
        "<br>\n",
        "Kita implementasikan dua pendekatan transformasi:<br>\n",
        "1. Menggunakan pandas (Python)<br>\n",
        "2. Menggunakan SQL di DuckDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXowbyPGrCsU"
      },
      "source": [
        "In[8]:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxxGCBcyrCsU"
      },
      "outputs": [],
      "source": [
        "def transform_with_pandas():\n",
        "    \"\"\"Transformasi data menggunakan pandas (Python)\"\"\"\n",
        "\n",
        "    # Baca ulang data untuk kejelasan tutorial\n",
        "    products_df = pd.read_csv('data/products.csv')\n",
        "    stores_df = pd.read_csv('data/stores.csv')\n",
        "    customers_df = pd.read_csv('data/customers_dirty.csv')\n",
        "    transactions_df = pd.read_csv('data/transactions.csv')\n",
        "\n",
        "    # 1. Transformasi dimensi produk\n",
        "    # Implementasi Slowly Changing Dimension (SCD) Type 2 sederhana\n",
        "    dim_product = products_df.copy()\n",
        "    dim_product['product_key'] = dim_product['product_id']  # Dalam kasus ini menggunakan ID yang sama\n",
        "    dim_product['effective_date'] = '2022-01-01'  # Tanggal efektif\n",
        "    dim_product['expiration_date'] = None  # Tidak berakhir karena ini adalah data awal\n",
        "    dim_product['current_flag'] = True  # Semua catatan aktif\n",
        "\n",
        "    dim_product = dim_product.rename(columns={\n",
        "        'name': 'product_name',\n",
        "        'base_cost': 'unit_cost',\n",
        "        'base_price': 'unit_price'\n",
        "    })\n",
        "\n",
        "    # 2. Transformasi dimensi toko\n",
        "    dim_store = stores_df.copy()\n",
        "    dim_store['store_key'] = dim_store['store_id']  # Dalam kasus ini menggunakan ID yang sama\n",
        "    dim_store['effective_date'] = '2022-01-01'  # Tanggal efektif\n",
        "    dim_store['expiration_date'] = None  # Tidak berakhir karena ini adalah data awal\n",
        "    dim_store['current_flag'] = True  # Semua catatan aktif\n",
        "\n",
        "    dim_store = dim_store.rename(columns={'name': 'store_name', 'type': 'store_type'})\n",
        "\n",
        "    # 3. Transformasi dimensi pelanggan (dengan pembersihan data)\n",
        "    # Pembersihan data pelanggan\n",
        "    dim_customer = customers_df.copy()\n",
        "\n",
        "    # Menangani nilai yang hilang\n",
        "    dim_customer['first_name'] = dim_customer['first_name'].fillna('Unknown')\n",
        "    dim_customer['last_name'] = dim_customer['last_name'].fillna('Unknown')\n",
        "    dim_customer['email'] = dim_customer['email'].fillna('unknown@example.com')\n",
        "\n",
        "    # Standarisasi kota (kapitalisasi yang konsisten)\n",
        "    dim_customer['city'] = dim_customer['city'].str.title()\n",
        "\n",
        "    # Menangani duplikat berdasarkan email (yang seharusnya unik)\n",
        "    dim_customer = dim_customer.drop_duplicates(subset=['email'], keep='first')\n",
        "\n",
        "    # Tambahkan kolom untuk SCD Type 2\n",
        "    dim_customer['customer_key'] = range(1, len(dim_customer) + 1)  # Buat surrogate key baru\n",
        "    dim_customer['effective_date'] = '2022-01-01'  # Tanggal efektif\n",
        "    dim_customer['expiration_date'] = None  # Tidak berakhir karena ini adalah data awal\n",
        "    dim_customer['current_flag'] = True  # Semua catatan aktif\n",
        "\n",
        "    # 4. Transformasi fakta penjualan\n",
        "    # Konversi string ke tanggal\n",
        "    transactions_df['date'] = pd.to_datetime(transactions_df['date'])\n",
        "\n",
        "    # Buat date_key berdasarkan format YYYYMMDD\n",
        "    transactions_df['date_key'] = transactions_df['date'].dt.strftime('%Y%m%d').astype(int)\n",
        "\n",
        "    # Gunakan pandas merge untuk menggabungkan dengan dimensi untuk mendapatkan kunci surrogate\n",
        "    # Simulasi fakta setelah dimensi dibangun\n",
        "    fact_sales = transactions_df.copy()\n",
        "\n",
        "    # Ganti sales_key dengan kunci surrogate\n",
        "    fact_sales['sales_key'] = range(1, len(fact_sales) + 1)\n",
        "\n",
        "    # Rename kolom untuk kejelasan\n",
        "    fact_sales = fact_sales.rename(columns={\n",
        "        'total_amount': 'sales_amount'\n",
        "    })\n",
        "\n",
        "    # Hapus kolom yang tidak diperlukan lagi\n",
        "    # fact_sales = fact_sales.drop(['date'], axis=1)\n",
        "\n",
        "    return dim_product, dim_store, dim_customer, fact_sales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIeGjf6-rCsV"
      },
      "source": [
        "Transformasi dengan pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OPPKBEorCsV"
      },
      "outputs": [],
      "source": [
        "dim_product_pd, dim_store_pd, dim_customer_pd, fact_sales_pd = transform_with_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BdRQTndrCsV"
      },
      "outputs": [],
      "source": [
        "print(\"Transformasi pandas selesai:\")\n",
        "print(f\"- Dimensi produk: {len(dim_product_pd)} baris\")\n",
        "print(f\"- Dimensi toko: {len(dim_store_pd)} baris\")\n",
        "print(f\"- Dimensi pelanggan: {len(dim_customer_pd)} baris\")\n",
        "print(f\"- Fakta penjualan: {len(fact_sales_pd)} baris\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJAAlnW4rCsV"
      },
      "outputs": [],
      "source": [
        "def transform_with_sql():\n",
        "    \"\"\"Transformasi data menggunakan SQL di DuckDB\"\"\"\n",
        "\n",
        "    # 1. Buat tabel staging untuk data sumber\n",
        "    conn.execute(\"CREATE OR REPLACE TABLE staging_products AS SELECT * FROM read_csv_auto('data/products.csv')\")\n",
        "    conn.execute(\"CREATE OR REPLACE TABLE staging_stores AS SELECT * FROM read_csv_auto('data/stores.csv')\")\n",
        "    conn.execute(\"CREATE OR REPLACE TABLE staging_customers AS SELECT * FROM read_csv_auto('data/customers_dirty.csv')\")\n",
        "    conn.execute(\"CREATE OR REPLACE TABLE staging_transactions AS SELECT * FROM read_csv_auto('data/transactions.csv')\")\n",
        "\n",
        "    # 2. Transformasi dimensi produk dengan SQL\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE staging_dim_product AS\n",
        "    SELECT\n",
        "        product_id AS product_key,\n",
        "        product_id,\n",
        "        name AS product_name,\n",
        "        category,\n",
        "        subcategory,\n",
        "        base_cost AS unit_cost,\n",
        "        base_price AS unit_price,\n",
        "        '2022-01-01'::DATE AS effective_date,\n",
        "        NULL::DATE AS expiration_date,\n",
        "        TRUE AS current_flag\n",
        "    FROM staging_products\n",
        "    \"\"\")\n",
        "\n",
        "    # 3. Transformasi dimensi toko dengan SQL\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE staging_dim_store AS\n",
        "    SELECT\n",
        "        store_id AS store_key,\n",
        "        store_id,\n",
        "        name AS store_name,\n",
        "        city,\n",
        "        region,\n",
        "        type AS store_type,\n",
        "        '2022-01-01'::DATE AS effective_date,\n",
        "        NULL::DATE AS expiration_date,\n",
        "        TRUE AS current_flag\n",
        "    FROM staging_stores\n",
        "    \"\"\")\n",
        "\n",
        "    # 4. Transformasi dimensi pelanggan dengan SQL (termasuk data cleansing)\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE staging_dim_customer AS\n",
        "    WITH clean_customers AS (\n",
        "        SELECT\n",
        "            customer_id,\n",
        "            COALESCE(first_name, 'Unknown') AS first_name,\n",
        "            COALESCE(last_name, 'Unknown') AS last_name,\n",
        "            COALESCE(email, 'unknown@example.com') AS email,\n",
        "            CASE\n",
        "                WHEN city IS NULL THEN 'Unknown'\n",
        "                ELSE UPPER(SUBSTRING(LOWER(city), 1, 1)) || SUBSTRING(LOWER(city), 2) -- Standarisasi kapitalisasi\n",
        "            END AS city,\n",
        "            membership,\n",
        "            -- Ambil hanya baris pertama untuk email duplikat\n",
        "            ROW_NUMBER() OVER (PARTITION BY email ORDER BY customer_id) AS rn\n",
        "        FROM staging_customers\n",
        "    )\n",
        "    SELECT\n",
        "        ROW_NUMBER() OVER (ORDER BY customer_id) AS customer_key,\n",
        "        customer_id,\n",
        "        first_name,\n",
        "        last_name,\n",
        "        email,\n",
        "        city,\n",
        "        membership,\n",
        "        '2022-01-01'::DATE AS effective_date,\n",
        "        NULL::DATE AS expiration_date,\n",
        "        TRUE AS current_flag\n",
        "    FROM clean_customers\n",
        "    WHERE rn = 1 -- Eliminasi duplikat\n",
        "    \"\"\")\n",
        "\n",
        "    # 5. Transformasi fakta penjualan dengan SQL\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE staging_fact_sales AS\n",
        "    SELECT\n",
        "        ROW_NUMBER() OVER (ORDER BY transaction_id, product_id) AS sales_key,\n",
        "        transaction_id,\n",
        "        STRFTIME(date, '%Y%m%d')::INTEGER AS date_key,\n",
        "        product_id AS product_key, -- Akan diganti nanti dengan JOIN\n",
        "        store_id AS store_key, -- Akan diganti nanti dengan JOIN\n",
        "        customer_id AS customer_key, -- Akan diganti nanti dengan JOIN\n",
        "        quantity,\n",
        "        unit_price,\n",
        "        unit_cost,\n",
        "        discount_pct,\n",
        "        discount_amount,\n",
        "        total_amount AS sales_amount,\n",
        "        profit AS profit_amount\n",
        "    FROM staging_transactions\n",
        "    \"\"\")\n",
        "\n",
        "    # Dapatkan jumlah baris\n",
        "    product_count = conn.execute(\"SELECT COUNT(*) FROM staging_dim_product\").fetchone()[0]\n",
        "    store_count = conn.execute(\"SELECT COUNT(*) FROM staging_dim_store\").fetchone()[0]\n",
        "    customer_count = conn.execute(\"SELECT COUNT(*) FROM staging_dim_customer\").fetchone()[0]\n",
        "    sales_count = conn.execute(\"SELECT COUNT(*) FROM staging_fact_sales\").fetchone()[0]\n",
        "\n",
        "    print(\"Transformasi SQL selesai:\")\n",
        "    print(f\"- Dimensi produk: {product_count} baris\")\n",
        "    print(f\"- Dimensi toko: {store_count} baris\")\n",
        "    print(f\"- Dimensi pelanggan: {customer_count} baris\")\n",
        "    print(f\"- Fakta penjualan: {sales_count} baris\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8VHU220rCsW"
      },
      "source": [
        "Transformasi dengan SQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4K1tliHrCsW"
      },
      "outputs": [],
      "source": [
        "transform_with_sql()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufo-uVEerCsW"
      },
      "source": [
        "### 5.3 Load - Memuat Data ke Data Warehouse<br>\n",
        "<br>\n",
        "Kita akan mengimplementasikan dua opsi loading:<br>\n",
        "1. Load dari pandas DataFrame<br>\n",
        "2. Load dari tabel staging SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QIxYOq8rCsW"
      },
      "source": [
        "In[12]:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R02FPcS5rCsW"
      },
      "outputs": [],
      "source": [
        "def load_from_pandas(dim_product, dim_store, dim_customer, fact_sales):\n",
        "    \"\"\"Memuat data dari pandas DataFrame ke data warehouse\"\"\"\n",
        "\n",
        "    # 1. Muat dimensi produk\n",
        "    conn.execute(\"DELETE FROM dim_product\")  # Bersihkan tabel sasaran\n",
        "    conn.execute(\"INSERT INTO dim_product SELECT * FROM dim_product\")\n",
        "\n",
        "    # 2. Muat dimensi toko\n",
        "    conn.execute(\"DELETE FROM dim_store\")  # Bersihkan tabel sasaran\n",
        "    conn.execute(\"INSERT INTO dim_store SELECT * FROM dim_store\")\n",
        "\n",
        "    # 3. Muat dimensi pelanggan\n",
        "    conn.execute(\"DELETE FROM dim_customer\")  # Bersihkan tabel sasaran\n",
        "    conn.execute(\"INSERT INTO dim_customer SELECT * FROM dim_customer\")\n",
        "\n",
        "    # 4. Muat fakta penjualan\n",
        "    # Sebelum memuat, kita perlu menyelaraskan kunci surrogate dengan dimensi\n",
        "\n",
        "    # Buat tabel sementara untuk fakta\n",
        "    conn.execute(\"CREATE OR REPLACE TABLE temp_fact_sales AS SELECT * FROM fact_sales\")\n",
        "\n",
        "    # 5. Muat fakta penjualan setelah pemetaan kunci\n",
        "    conn.execute(\"\"\"\n",
        "    INSERT INTO fact_sales\n",
        "    SELECT\n",
        "        f.sales_key,\n",
        "        f.transaction_id,\n",
        "        f.date_key,\n",
        "        p.product_key,\n",
        "        s.store_key,\n",
        "        c.customer_key,\n",
        "        f.quantity,\n",
        "        f.unit_price,\n",
        "        f.unit_cost,\n",
        "        f.discount_pct,\n",
        "        f.discount_amount,\n",
        "        f.sales_amount,\n",
        "        f.profit_amount\n",
        "    FROM temp_fact_sales f\n",
        "    JOIN dim_product p ON f.product_key = p.product_id\n",
        "    JOIN dim_store s ON f.store_key = s.store_id\n",
        "    JOIN dim_customer c ON f.customer_key = c.customer_id\n",
        "    \"\"\")\n",
        "\n",
        "    # Hapus tabel sementara\n",
        "    conn.execute(\"DROP TABLE temp_fact_sales\")\n",
        "\n",
        "    # Menghitung jumlah baris yang dimuat\n",
        "    product_count = conn.execute(\"SELECT COUNT(*) FROM dim_product\").fetchone()[0]\n",
        "    store_count = conn.execute(\"SELECT COUNT(*) FROM dim_store\").fetchone()[0]\n",
        "    customer_count = conn.execute(\"SELECT COUNT(*) FROM dim_customer\").fetchone()[0]\n",
        "    sales_count = conn.execute(\"SELECT COUNT(*) FROM fact_sales\").fetchone()[0]\n",
        "\n",
        "    print(\"Data dari pandas berhasil dimuat ke data warehouse:\")\n",
        "    print(f\"- Dimensi produk: {product_count} baris\")\n",
        "    print(f\"- Dimensi toko: {store_count} baris\")\n",
        "    print(f\"- Dimensi pelanggan: {customer_count} baris\")\n",
        "    print(f\"- Fakta penjualan: {sales_count} baris\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvXr4N33rCsX"
      },
      "outputs": [],
      "source": [
        "def load_from_staging():\n",
        "    \"\"\"Memuat data dari tabel staging SQL ke data warehouse\"\"\"\n",
        "\n",
        "    # 1. Muat dimensi produk\n",
        "    conn.execute(\"DELETE FROM dim_product\")  # Bersihkan tabel sasaran\n",
        "    conn.execute(\"INSERT INTO dim_product SELECT * FROM staging_dim_product\")\n",
        "\n",
        "    # 2. Muat dimensi toko\n",
        "    conn.execute(\"DELETE FROM dim_store\")  # Bersihkan tabel sasaran\n",
        "    conn.execute(\"INSERT INTO dim_store SELECT * FROM staging_dim_store\")\n",
        "\n",
        "    # 3. Muat dimensi pelanggan\n",
        "    conn.execute(\"DELETE FROM dim_customer\")  # Bersihkan tabel sasaran\n",
        "    conn.execute(\"INSERT INTO dim_customer SELECT * FROM staging_dim_customer\")\n",
        "\n",
        "    # 4. Muat fakta penjualan dengan pemetaan kunci yang benar\n",
        "    conn.execute(\"DELETE FROM fact_sales\")  # Bersihkan tabel sasaran\n",
        "    conn.execute(\"\"\"\n",
        "    INSERT INTO fact_sales\n",
        "    SELECT\n",
        "        f.sales_key,\n",
        "        f.transaction_id,\n",
        "        f.date_key,\n",
        "        p.product_key,\n",
        "        s.store_key,\n",
        "        c.customer_key,\n",
        "        f.quantity,\n",
        "        f.unit_price,\n",
        "        f.unit_cost,\n",
        "        f.discount_pct,\n",
        "        f.discount_amount,\n",
        "        f.sales_amount,\n",
        "        f.profit_amount\n",
        "    FROM staging_fact_sales f\n",
        "    JOIN dim_product p ON f.product_key = p.product_id\n",
        "    JOIN dim_store s ON f.store_key = s.store_id\n",
        "    JOIN dim_customer c ON f.customer_key = c.customer_id\n",
        "    \"\"\")\n",
        "\n",
        "    # Menghitung jumlah baris yang dimuat\n",
        "    product_count = conn.execute(\"SELECT COUNT(*) FROM dim_product\").fetchone()[0]\n",
        "    store_count = conn.execute(\"SELECT COUNT(*) FROM dim_store\").fetchone()[0]\n",
        "    customer_count = conn.execute(\"SELECT COUNT(*) FROM dim_customer\").fetchone()[0]\n",
        "    sales_count = conn.execute(\"SELECT COUNT(*) FROM fact_sales\").fetchone()[0]\n",
        "\n",
        "    print(\"Data dari staging berhasil dimuat ke data warehouse:\")\n",
        "    print(f\"- Dimensi produk: {product_count} baris\")\n",
        "    print(f\"- Dimensi toko: {store_count} baris\")\n",
        "    print(f\"- Dimensi pelanggan: {customer_count} baris\")\n",
        "    print(f\"- Fakta penjualan: {sales_count} baris\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzvT8Ge0rCsX"
      },
      "source": [
        "Pilih salah satu metode loading:<br>\n",
        "load_from_pandas(dim_product_pd, dim_store_pd, dim_customer_pd, fact_sales_pd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-RNLnllrCsX"
      },
      "outputs": [],
      "source": [
        "load_from_staging()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8UnBKVLrCsX"
      },
      "source": [
        "## 6. Implementasi Snowflake Schema<br>\n",
        "<br>\n",
        "Mari buat versi Snowflake Schema dari model kita dengan menormalisasi dimensi produk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBlENM6erCsX"
      },
      "outputs": [],
      "source": [
        "def create_snowflake_schema():\n",
        "    \"\"\"Mengimplementasikan Snowflake Schema dari dimensi produk\"\"\"\n",
        "\n",
        "    # Drop existing tables in the correct order to handle dependencies\n",
        "    conn.execute(\"DROP TABLE IF EXISTS dim_product_snowflake\")\n",
        "    conn.execute(\"DROP TABLE IF EXISTS dim_subcategory\")\n",
        "    conn.execute(\"DROP TABLE IF EXISTS dim_category\")\n",
        "\n",
        "    # 1. Buat tabel kategori\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE TABLE dim_category AS\n",
        "    SELECT\n",
        "        ROW_NUMBER() OVER (ORDER BY category) AS category_key,\n",
        "        category AS category_name\n",
        "    FROM (SELECT DISTINCT category FROM dim_product)\n",
        "    \"\"\")\n",
        "\n",
        "    # 2. Buat tabel subkategori\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE TABLE dim_subcategory AS\n",
        "    WITH subcategory_data AS (\n",
        "        SELECT DISTINCT\n",
        "            subcategory,\n",
        "            category\n",
        "        FROM dim_product\n",
        "    )\n",
        "    SELECT\n",
        "        ROW_NUMBER() OVER (ORDER BY s.subcategory) AS subcategory_key,\n",
        "        s.subcategory AS subcategory_name,\n",
        "        c.category_key\n",
        "    FROM subcategory_data s\n",
        "    JOIN dim_category c ON s.category = c.category_name\n",
        "    \"\"\")\n",
        "\n",
        "    # 3. Buat versi snowflake dari tabel produk\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE TABLE dim_product_snowflake AS\n",
        "    SELECT\n",
        "        p.product_key,\n",
        "        p.product_id,\n",
        "        p.product_name,\n",
        "        c.category_key,\n",
        "        s.subcategory_key,\n",
        "        p.unit_cost,\n",
        "        p.unit_price,\n",
        "        p.effective_date,\n",
        "        p.expiration_date,\n",
        "        p.current_flag\n",
        "    FROM dim_product p\n",
        "    JOIN dim_category c ON p.category = c.category_name\n",
        "    JOIN dim_subcategory s ON p.subcategory = s.subcategory_name AND s.category_key = c.category_key\n",
        "    \"\"\")\n",
        "\n",
        "    # Menghitung jumlah baris\n",
        "    category_count = conn.execute(\"SELECT COUNT(*) FROM dim_category\").fetchone()[0]\n",
        "    subcategory_count = conn.execute(\"SELECT COUNT(*) FROM dim_subcategory\").fetchone()[0]\n",
        "    product_count = conn.execute(\"SELECT COUNT(*) FROM dim_product_snowflake\").fetchone()[0]\n",
        "\n",
        "    print(\"Snowflake schema berhasil dibuat:\")\n",
        "    print(f\"- Dimensi kategori: {category_count} baris\")\n",
        "    print(f\"- Dimensi subkategori: {subcategory_count} baris\")\n",
        "    print(f\"- Dimensi produk (snowflake): {product_count} baris\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX4ZDYwLrCsb"
      },
      "source": [
        "Buat snowflake schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESaq5NcvrCsb"
      },
      "outputs": [],
      "source": [
        "create_snowflake_schema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvcBA1WPrCsb"
      },
      "source": [
        "## 7. Implementasi Fact Constellation (Galaxy Schema)<br>\n",
        "<br>\n",
        "Sekarang kita akan menambahkan tabel fakta kedua untuk inventaris produk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gjS6PdYrCsc"
      },
      "outputs": [],
      "source": [
        "def create_fact_constellation():\n",
        "    \"\"\"Mengimplementasikan Fact Constellation dengan menambahkan tabel fakta inventaris\"\"\"\n",
        "\n",
        "    # 1. Buat tabel fakta inventaris\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE fact_inventory (\n",
        "        inventory_key INTEGER PRIMARY KEY,\n",
        "        date_key INTEGER,\n",
        "        product_key INTEGER,\n",
        "        store_key INTEGER,\n",
        "        quantity_on_hand INTEGER,\n",
        "        quantity_received INTEGER,\n",
        "        quantity_sold INTEGER,\n",
        "        stock_value DECIMAL(10,2),\n",
        "\n",
        "        FOREIGN KEY (date_key) REFERENCES dim_date(date_key),\n",
        "        FOREIGN KEY (product_key) REFERENCES dim_product(product_key),\n",
        "        FOREIGN KEY (store_key) REFERENCES dim_store(store_key)\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    # 2. Buat data inventaris berdasarkan data penjualan (simulasi)\n",
        "    conn.execute(\"\"\"\n",
        "    -- Data inventaris untuk bulan terakhir\n",
        "    WITH latest_month AS (\n",
        "        SELECT\n",
        "            MAX(date) as max_date,\n",
        "            EXTRACT(YEAR FROM MAX(date)) as year,\n",
        "            EXTRACT(MONTH FROM MAX(date)) as month\n",
        "        FROM dim_date\n",
        "    ),\n",
        "\n",
        "    month_dates AS (\n",
        "        SELECT\n",
        "            date_key,\n",
        "            date\n",
        "        FROM\n",
        "            dim_date,\n",
        "            latest_month\n",
        "        WHERE\n",
        "            EXTRACT(YEAR FROM date) = latest_month.year AND\n",
        "            EXTRACT(MONTH FROM date) = latest_month.month\n",
        "        ORDER BY\n",
        "            date\n",
        "    ),\n",
        "\n",
        "    store_products AS (\n",
        "        SELECT DISTINCT\n",
        "            s.store_key,\n",
        "            p.product_key\n",
        "        FROM\n",
        "            dim_store s,\n",
        "            dim_product p\n",
        "        ORDER BY\n",
        "            s.store_key, p.product_key\n",
        "        LIMIT 300 -- Batasi kombinasi untuk sampel\n",
        "    )\n",
        "\n",
        "    INSERT INTO fact_inventory\n",
        "    WITH inventory_data AS (\n",
        "        SELECT\n",
        "            md.date_key,\n",
        "            sp.store_key,\n",
        "            sp.product_key,\n",
        "            -- Acak untuk data contoh\n",
        "            CAST(RANDOM() * 100 AS INTEGER) AS base_qty_on_hand,\n",
        "            CAST(RANDOM() * 20 AS INTEGER) AS base_qty_received,\n",
        "            CAST(RANDOM() * 15 AS INTEGER) AS base_qty_sold\n",
        "        FROM\n",
        "            month_dates md\n",
        "        CROSS JOIN\n",
        "            store_products sp\n",
        "    ),\n",
        "\n",
        "    -- Tambahkan running total untuk membuat data inventaris yang masuk akal\n",
        "    running_inventory AS (\n",
        "        SELECT\n",
        "            id.date_key,\n",
        "            id.store_key,\n",
        "            id.product_key,\n",
        "            id.base_qty_received AS quantity_received,\n",
        "            id.base_qty_sold AS quantity_sold,\n",
        "            CASE\n",
        "                WHEN ROW_NUMBER() OVER (PARTITION BY id.store_key, id.product_key ORDER BY id.date_key) = 1\n",
        "                THEN id.base_qty_on_hand\n",
        "                ELSE NULL -- Akan diisi nanti\n",
        "            END AS initial_qty\n",
        "        FROM\n",
        "            inventory_data id\n",
        "    ),\n",
        "\n",
        "    final_inventory AS (\n",
        "        SELECT\n",
        "            date_key,\n",
        "            store_key,\n",
        "            product_key,\n",
        "            quantity_received,\n",
        "            quantity_sold,\n",
        "            SUM(COALESCE(initial_qty, 0)) OVER (\n",
        "                PARTITION BY store_key, product_key\n",
        "                ORDER BY date_key\n",
        "                ROWS UNBOUNDED PRECEDING\n",
        "            )\n",
        "            + SUM(quantity_received) OVER (\n",
        "                PARTITION BY store_key, product_key\n",
        "                ORDER BY date_key\n",
        "                ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
        "            )\n",
        "            - SUM(quantity_sold) OVER (\n",
        "                PARTITION BY store_key, product_key\n",
        "                ORDER BY date_key\n",
        "                ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
        "            )\n",
        "            + COALESCE(initial_qty, 0)\n",
        "            AS quantity_on_hand\n",
        "        FROM\n",
        "            running_inventory\n",
        "    )\n",
        "\n",
        "    SELECT\n",
        "        ROW_NUMBER() OVER (ORDER BY fi.date_key, fi.store_key, fi.product_key) AS inventory_key,\n",
        "        fi.date_key,\n",
        "        fi.product_key,  -- Specify table alias\n",
        "        fi.store_key,\n",
        "        fi.quantity_on_hand,\n",
        "        fi.quantity_received,\n",
        "        fi.quantity_sold,\n",
        "        fi.quantity_on_hand * dp.unit_cost AS stock_value\n",
        "    FROM\n",
        "        final_inventory fi\n",
        "    JOIN\n",
        "        dim_product dp ON fi.product_key = dp.product_key\n",
        "    \"\"\")\n",
        "\n",
        "    # Menghitung jumlah baris\n",
        "    inventory_count = conn.execute(\"SELECT COUNT(*) FROM fact_inventory\").fetchone()[0]\n",
        "\n",
        "    print(f\"Fact Constellation berhasil dibuat dengan tabel fakta inventaris ({inventory_count} baris)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCKN8dC6rCsc"
      },
      "source": [
        "Buat fact constellation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJdssFYCrCsc"
      },
      "outputs": [],
      "source": [
        "create_fact_constellation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gANdHXwsrCsc"
      },
      "source": [
        "## 8. Implementasi SCD (Slowly Changing Dimension) Type 2<br>\n",
        "<br>\n",
        "Tunjukkan bagaimana menangani perubahan data yang perlu dilacak secara historis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKNRvv5irCsc"
      },
      "outputs": [],
      "source": [
        "def implement_scd_type2():\n",
        "    \"\"\"Implementasi SCD Type 2 untuk dimensi pelanggan\"\"\"\n",
        "\n",
        "    # 1. Simulasi perubahan data (dengan pandas)\n",
        "    # Ambil beberapa pelanggan dan ubah data mereka\n",
        "    customers_df = pd.read_csv('data/customers.csv')\n",
        "\n",
        "    # Pilih 10 pelanggan secara acak untuk diubah datanya\n",
        "    updated_customers = customers_df.sample(10).copy()\n",
        "\n",
        "    # Ubah beberapa data\n",
        "    for idx, row in updated_customers.iterrows():\n",
        "        if np.random.random() < 0.5:\n",
        "            # Perubahan kota\n",
        "            updated_customers.loc[idx, 'city'] = np.random.choice(['Jakarta Selatan', 'Bandung Barat',\n",
        "                                                              'Surabaya Timur', 'Medan Utara'])\n",
        "        else:\n",
        "            # Perubahan membership\n",
        "            current_membership = updated_customers.loc[idx, 'membership']\n",
        "            new_membership = np.random.choice(['Silver', 'Gold', 'Platinum', 'Regular'])\n",
        "            # Pastikan membership baru berbeda\n",
        "            while new_membership == current_membership:\n",
        "                new_membership = np.random.choice(['Silver', 'Gold', 'Platinum', 'Regular'])\n",
        "            updated_customers.loc[idx, 'membership'] = new_membership\n",
        "\n",
        "    # Simpan pelanggan yang diperbarui untuk diekstrak\n",
        "    updated_customers.to_csv('data/updated_customers.csv', index=False)\n",
        "\n",
        "    # 2. Ekstrak dan bersihkan data yang diperbarui\n",
        "    conn.execute(\"CREATE OR REPLACE TABLE staging_updated_customers AS SELECT * FROM read_csv_auto('data/updated_customers.csv')\")\n",
        "\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE staging_updated_customers_clean AS\n",
        "    SELECT\n",
        "        customer_id,\n",
        "        COALESCE(first_name, 'Unknown') AS first_name,\n",
        "        COALESCE(last_name, 'Unknown') AS last_name,\n",
        "        COALESCE(email, 'unknown@example.com') AS email,\n",
        "        CASE\n",
        "            WHEN city IS NULL THEN 'Unknown'\n",
        "            ELSE LOWER(city) -- Standarisasi menjadi lowercase karena INITCAP tidak ada di DuckDB\n",
        "        END AS city,\n",
        "        membership,\n",
        "        CURRENT_DATE AS effective_date\n",
        "    FROM staging_updated_customers\n",
        "    \"\"\")\n",
        "\n",
        "    # 3. Identifikasi perubahan\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE customer_changes AS\n",
        "    SELECT\n",
        "        s.customer_id,\n",
        "        s.first_name,\n",
        "        s.last_name,\n",
        "        s.email,\n",
        "        s.city,\n",
        "        s.membership,\n",
        "        s.effective_date,\n",
        "        CASE\n",
        "            WHEN d.customer_id IS NULL THEN 'NEW'\n",
        "            WHEN (s.city != d.city OR s.membership != d.membership) THEN 'CHANGED'\n",
        "            ELSE 'UNCHANGED'\n",
        "        END AS change_type\n",
        "    FROM\n",
        "        staging_updated_customers_clean s\n",
        "    LEFT JOIN\n",
        "        dim_customer d\n",
        "    ON\n",
        "        s.customer_id = d.customer_id\n",
        "        AND d.current_flag = TRUE\n",
        "    \"\"\")\n",
        "\n",
        "    # 4. Implementasi SCD Type 2 - Mengakhiri catatan lama\n",
        "    conn.execute(\"\"\"\n",
        "    UPDATE dim_customer\n",
        "    SET\n",
        "        current_flag = FALSE,\n",
        "        expiration_date = CURRENT_DATE - INTERVAL '1 day'\n",
        "    WHERE\n",
        "        customer_id IN (SELECT customer_id FROM customer_changes WHERE change_type = 'CHANGED')\n",
        "        AND current_flag = TRUE\n",
        "    \"\"\")\n",
        "\n",
        "    # 5. Implementasi SCD Type 2 - Menambahkan catatan baru\n",
        "    conn.execute(\"\"\"\n",
        "    INSERT INTO dim_customer\n",
        "    SELECT\n",
        "        (SELECT MAX(customer_key) FROM dim_customer) + ROW_NUMBER() OVER (ORDER BY customer_id) AS customer_key,\n",
        "        customer_id,\n",
        "        first_name,\n",
        "        last_name,\n",
        "        email,\n",
        "        city,\n",
        "        membership,\n",
        "        effective_date,\n",
        "        NULL AS expiration_date,\n",
        "        TRUE AS current_flag\n",
        "    FROM\n",
        "        customer_changes\n",
        "    WHERE\n",
        "        change_type = 'CHANGED'\n",
        "    \"\"\")\n",
        "\n",
        "    # Menampilkan perubahan\n",
        "    changes_count = conn.execute(\"SELECT change_type, COUNT(*) FROM customer_changes GROUP BY change_type\").fetchdf()\n",
        "    print(\"Perubahan dimensi pelanggan:\")\n",
        "    print(changes_count)\n",
        "\n",
        "    # Tampilkan contoh historis\n",
        "    if conn.execute(\"SELECT COUNT(*) FROM customer_changes WHERE change_type = 'CHANGED'\").fetchone()[0] > 0:\n",
        "        changed_id = conn.execute(\"SELECT customer_id FROM customer_changes WHERE change_type = 'CHANGED' LIMIT 1\").fetchone()[0]\n",
        "\n",
        "        history = conn.execute(f\"\"\"\n",
        "            SELECT\n",
        "                customer_key,\n",
        "                customer_id,\n",
        "                city,\n",
        "                membership,\n",
        "                effective_date,\n",
        "                expiration_date,\n",
        "                current_flag\n",
        "            FROM\n",
        "                dim_customer\n",
        "            WHERE\n",
        "                customer_id = {changed_id}\n",
        "            ORDER BY\n",
        "                effective_date\n",
        "        \"\"\").fetchdf()\n",
        "\n",
        "        print(f\"\\nContoh riwayat untuk pelanggan {changed_id}:\")\n",
        "        print(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mprVJO09rCsc"
      },
      "source": [
        "Implementasi SCD Type 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9YEjYeWrCsd"
      },
      "outputs": [],
      "source": [
        "implement_scd_type2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm8Nj7RJrCsd"
      },
      "source": [
        "## 9. Implementasi Incremental ETL<br>\n",
        "<br>\n",
        "Kita akan menunjukkan bagaimana melakukan ETL inkremental, di mana hanya data baru yang diproses:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC-Vhs_ZrCsd"
      },
      "outputs": [],
      "source": [
        "def generate_incremental_data():\n",
        "    \"\"\"Menghasilkan data baru untuk diproses inkremental\"\"\"\n",
        "\n",
        "    # 1. Baca data transaksi yang ada\n",
        "    transactions_df = pd.read_csv('data/transactions.csv')\n",
        "\n",
        "    # 2. Buat transaksi baru dengan tanggal yang lebih baru\n",
        "    new_transactions = []\n",
        "\n",
        "    start_date = datetime(2024, 1, 1)\n",
        "    end_date = datetime(2024, 1, 10)\n",
        "\n",
        "    for i in range(500):  # Buat 500 transaksi baru\n",
        "        tx_date = start_date + timedelta(days=np.random.randint(0, (end_date-start_date).days))\n",
        "\n",
        "        # Pilih store, customer, dan product secara acak dari data yang ada\n",
        "        store_id = np.random.choice(transactions_df['store_id'].unique())\n",
        "        customer_id = np.random.choice(transactions_df['customer_id'].unique())\n",
        "        product_id = np.random.choice(transactions_df['product_id'].unique())\n",
        "\n",
        "        # Dapatkan data produk\n",
        "        product_info = transactions_df[transactions_df['product_id'] == product_id].iloc[0]\n",
        "\n",
        "        # Simulasi variasi harga\n",
        "        price_variance = np.random.uniform(0.9, 1.1)\n",
        "        price = round(product_info['unit_price'] * price_variance, 2)\n",
        "\n",
        "        cost_variance = np.random.uniform(0.95, 1.05)\n",
        "        cost = round(product_info['unit_cost'] * cost_variance, 2)\n",
        "\n",
        "        quantity = np.random.randint(1, 6)\n",
        "\n",
        "        # Diskon kadang diberikan\n",
        "        discount_pct = 0\n",
        "        if np.random.random() < 0.3:  # 30% transaksi mendapat diskon\n",
        "            discount_pct = np.random.choice([5, 10, 15, 20, 25, 50]) / 100\n",
        "\n",
        "        discount_amount = round(price * quantity * discount_pct, 2)\n",
        "        total = round(price * quantity - discount_amount, 2)\n",
        "        profit = round(total - (cost * quantity), 2)\n",
        "\n",
        "        new_transactions.append({\n",
        "            'transaction_id': f'TX-NEW-{i+1}',\n",
        "            'date': tx_date.strftime('%Y-%m-%d'),\n",
        "            'store_id': store_id,\n",
        "            'customer_id': customer_id,\n",
        "            'product_id': product_id,\n",
        "            'quantity': quantity,\n",
        "            'unit_price': price,\n",
        "            'unit_cost': cost,\n",
        "            'discount_pct': discount_pct,\n",
        "            'discount_amount': discount_amount,\n",
        "            'total_amount': total,\n",
        "            'profit': profit\n",
        "        })\n",
        "\n",
        "    # Simpan data baru\n",
        "    new_tx_df = pd.DataFrame(new_transactions)\n",
        "    new_tx_df.to_csv('data/new_transactions.csv', index=False)\n",
        "\n",
        "    print(f\"Generated {len(new_transactions)} new transactions for incremental processing\")\n",
        "    return new_tx_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUQ_LaPLrCsd"
      },
      "outputs": [],
      "source": [
        "def incremental_etl():\n",
        "    \"\"\"Proses ETL inkremental hanya untuk data baru\"\"\"\n",
        "\n",
        "    # 1. Ekstrak data baru\n",
        "    # Generate data baru dahulu\n",
        "    generate_incremental_data()\n",
        "\n",
        "    # Dapatkan tanggal terakhir yang sudah diproses\n",
        "    last_date = conn.execute(\"\"\"\n",
        "        SELECT MAX(d.date)\n",
        "        FROM fact_sales f\n",
        "        JOIN dim_date d ON f.date_key = d.date_key\n",
        "    \"\"\").fetchone()[0]\n",
        "\n",
        "    print(f\"Tanggal terakhir terproses: {last_date}\")\n",
        "\n",
        "    # Ekstrak data baru dan filter transaksi yang sudah ada\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE staging_new_transactions AS\n",
        "    SELECT * FROM read_csv_auto('data/new_transactions.csv') t\n",
        "    WHERE date::DATE > ?\n",
        "    AND NOT EXISTS (\n",
        "        SELECT 1 FROM fact_sales fs\n",
        "        WHERE fs.transaction_id = t.transaction_id\n",
        "    )\n",
        "    \"\"\", [last_date])\n",
        "\n",
        "    # Hitung jumlah transaksi baru\n",
        "    new_count = conn.execute(\"SELECT COUNT(*) FROM staging_new_transactions\").fetchone()[0]\n",
        "    print(f\"Ditemukan {new_count} transaksi baru yang unik untuk diproses\")\n",
        "\n",
        "    # Exit early if no new transactions to process\n",
        "    if new_count == 0:\n",
        "        print(\"Tidak ada transaksi baru untuk diproses\")\n",
        "        return\n",
        "\n",
        "    # 1.5 Identifikasi dan tambahkan tanggal baru ke dimensi tanggal\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE staging_new_dates AS\n",
        "    SELECT DISTINCT\n",
        "        strftime(date::DATE, '%Y%m%d')::INTEGER AS date_key,\n",
        "        date::DATE AS date,\n",
        "        EXTRACT(YEAR FROM date::DATE) AS year,\n",
        "        EXTRACT(MONTH FROM date::DATE) AS month,\n",
        "        EXTRACT(DAY FROM date::DATE) AS day,\n",
        "        EXTRACT(DOW FROM date::DATE) AS day_of_week\n",
        "    FROM staging_new_transactions\n",
        "    WHERE strftime(date::DATE, '%Y%m%d')::INTEGER NOT IN (SELECT date_key FROM dim_date)\n",
        "    \"\"\")\n",
        "\n",
        "    # Hitung jumlah tanggal baru\n",
        "    new_dates_count = conn.execute(\"SELECT COUNT(*) FROM staging_new_dates\").fetchone()[0]\n",
        "    print(f\"Menambahkan {new_dates_count} tanggal baru ke dalam dimensi tanggal\")\n",
        "\n",
        "    # Tambahkan tanggal baru ke dimensi tanggal jika ada\n",
        "    if new_dates_count > 0:\n",
        "        conn.execute(\"\"\"\n",
        "        INSERT INTO dim_date (date_key, date, year, month, day, day_of_week)\n",
        "        SELECT date_key, date, year, month, day, day_of_week\n",
        "        FROM staging_new_dates\n",
        "        \"\"\")\n",
        "\n",
        "    # 2. Dapatkan sales_key terakhir dari fact_sales untuk incremental key generation\n",
        "    max_sales_key = conn.execute(\"SELECT COALESCE(MAX(sales_key), 0) FROM fact_sales\").fetchone()[0]\n",
        "    print(f\"Sales key terakhir: {max_sales_key}\")\n",
        "\n",
        "    # Dapatkan daftar dari semua sales_key yang sudah ada untuk pengecekan\n",
        "    existing_keys = set()\n",
        "    for row in conn.execute(\"SELECT sales_key FROM fact_sales\").fetchall():\n",
        "        existing_keys.add(row[0])\n",
        "\n",
        "    # Dapatkan daftar dari semua transaction_id yang sudah ada untuk pengecekan\n",
        "    existing_transactions = set()\n",
        "    for row in conn.execute(\"SELECT transaction_id FROM fact_sales\").fetchall():\n",
        "        existing_transactions.add(row[0])\n",
        "\n",
        "    # 2. Buat staging untuk fact sales dengan perhitungan kunci yang benar-benar aman\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE staging_fact_sales_incremental AS\n",
        "    SELECT\n",
        "        0 AS sales_key, -- Placeholder, akan diupdate nanti\n",
        "        t.transaction_id,\n",
        "        strftime(t.date::DATE, '%Y%m%d')::INTEGER AS date_key,\n",
        "        t.product_id AS product_key,\n",
        "        t.store_id AS store_key,\n",
        "        t.customer_id AS customer_key,\n",
        "        t.quantity,\n",
        "        t.unit_price,\n",
        "        t.unit_cost,\n",
        "        t.discount_pct,\n",
        "        t.discount_amount,\n",
        "        t.total_amount AS sales_amount,\n",
        "        t.profit AS profit_amount\n",
        "    FROM staging_new_transactions t\n",
        "    WHERE t.transaction_id NOT IN (\n",
        "        SELECT transaction_id FROM fact_sales\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    # Update kunci sales dengan pengecekan keunikan\n",
        "    new_rows = conn.execute(\"SELECT transaction_id FROM staging_fact_sales_incremental\").fetchall()\n",
        "    start_key = max_sales_key + 1\n",
        "\n",
        "    for i, row in enumerate(new_rows):\n",
        "        transaction_id = row[0]\n",
        "        new_key = start_key + i\n",
        "\n",
        "        # Pastikan kunci baru tidak ada dalam daftar existing_keys\n",
        "        while new_key in existing_keys:\n",
        "            new_key += 1\n",
        "\n",
        "        # Update record dengan kunci yang aman\n",
        "        conn.execute(\"\"\"\n",
        "        UPDATE staging_fact_sales_incremental\n",
        "        SET sales_key = ?\n",
        "        WHERE transaction_id = ?\n",
        "        \"\"\", [new_key, transaction_id])\n",
        "\n",
        "        # Tambahkan ke set existing_keys untuk pengecekan berikutnya\n",
        "        existing_keys.add(new_key)\n",
        "\n",
        "    # Final check - pastikan tidak ada kunci duplikat dalam staging\n",
        "    dup_count = conn.execute(\"\"\"\n",
        "    SELECT COUNT(*) FROM (\n",
        "        SELECT sales_key FROM staging_fact_sales_incremental\n",
        "        GROUP BY sales_key\n",
        "        HAVING COUNT(*) > 1\n",
        "    )\n",
        "    \"\"\").fetchone()[0]\n",
        "\n",
        "    if dup_count > 0:\n",
        "        print(f\"PERINGATAN: Ditemukan {dup_count} kunci duplikat dalam staging. Transaksi tidak akan dimasukkan.\")\n",
        "        return\n",
        "\n",
        "    # Verifikasi bahwa kunci sales_key di staging tidak ada di fact_sales\n",
        "    overlap_keys = conn.execute(\"\"\"\n",
        "    SELECT COUNT(*) FROM staging_fact_sales_incremental s\n",
        "    WHERE s.sales_key IN (SELECT sales_key FROM fact_sales)\n",
        "    \"\"\").fetchone()[0]\n",
        "\n",
        "    if overlap_keys > 0:\n",
        "        print(f\"PERINGATAN: Ditemukan {overlap_keys} sales_key yang tumpang tindih. Transaksi tidak akan dimasukkan.\")\n",
        "        return\n",
        "\n",
        "    # Verifikasi bahwa transaction_id di staging tidak ada di fact_sales\n",
        "    overlap_transactions = conn.execute(\"\"\"\n",
        "    SELECT COUNT(*) FROM staging_fact_sales_incremental s\n",
        "    WHERE s.transaction_id IN (SELECT transaction_id FROM fact_sales)\n",
        "    \"\"\").fetchone()[0]\n",
        "\n",
        "    if overlap_transactions > 0:\n",
        "        print(f\"PERINGATAN: Ditemukan {overlap_transactions} transaction_id yang tumpang tindih. Transaksi tidak akan dimasukkan.\")\n",
        "        return\n",
        "\n",
        "    # 3. Load data baru - gunakan INSERT tanpa JOIN kompleks untuk mengurangi risiko\n",
        "    conn.execute(\"\"\"\n",
        "    INSERT INTO fact_sales (\n",
        "        sales_key, transaction_id, date_key, product_key, store_key,\n",
        "        customer_key, quantity, unit_price, unit_cost, discount_pct,\n",
        "        discount_amount, sales_amount, profit_amount\n",
        "    )\n",
        "    SELECT\n",
        "        f.sales_key, f.transaction_id, f.date_key,\n",
        "        f.product_key, f.store_key, f.customer_key,\n",
        "        f.quantity, f.unit_price, f.unit_cost,\n",
        "        f.discount_pct, f.discount_amount, f.sales_amount, f.profit_amount\n",
        "    FROM staging_fact_sales_incremental f\n",
        "    \"\"\")\n",
        "\n",
        "    # Dapatkan jumlah total rekaman setelah proses inkremental\n",
        "    inserted_count = conn.execute(\"SELECT COUNT(*) FROM staging_fact_sales_incremental\").fetchone()[0]\n",
        "    total_count = conn.execute(\"SELECT COUNT(*) FROM fact_sales\").fetchone()[0]\n",
        "    print(f\"Berhasil menambahkan {inserted_count} transaksi baru\")\n",
        "    print(f\"Total transaksi dalam data warehouse setelah proses inkremental: {total_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAzpsa05rCsd"
      },
      "source": [
        "Jalankan ETL inkremental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tSaLRIarCsd"
      },
      "outputs": [],
      "source": [
        "incremental_etl()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz-MuT8RrCse"
      },
      "source": [
        "## 10. Class ETLPipeline untuk Mengotomatisasi Semua Proses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNEHgwZorCse"
      },
      "outputs": [],
      "source": [
        "class ETLPipeline:\n",
        "    \"\"\"Class untuk mengotomatisasi proses ETL\"\"\"\n",
        "\n",
        "    def __init__(self, db_path='retail_dw.db'):\n",
        "        \"\"\"Inisialisasi pipeline\"\"\"\n",
        "        self.conn = duckdb.connect(db_path)\n",
        "        self.initialized = False\n",
        "        self.log_table_setup()\n",
        "\n",
        "    def log_table_setup(self):\n",
        "        \"\"\"Membuat tabel log untuk melacak proses ETL\"\"\"\n",
        "        self.conn.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS etl_log (\n",
        "            log_id INTEGER PRIMARY KEY,\n",
        "            process_name VARCHAR,\n",
        "            start_time TIMESTAMP,\n",
        "            end_time TIMESTAMP,\n",
        "            records_processed INTEGER,\n",
        "            status VARCHAR,\n",
        "            message VARCHAR\n",
        "        )\n",
        "        \"\"\")\n",
        "\n",
        "    def log_process_start(self, process_name):\n",
        "        \"\"\"Mencatat mulainya proses ETL\"\"\"\n",
        "        log_id = self.conn.execute(\"SELECT COALESCE(MAX(log_id), 0) + 1 FROM etl_log\").fetchone()[0]\n",
        "        self.conn.execute(\"\"\"\n",
        "        INSERT INTO etl_log (log_id, process_name, start_time, status)\n",
        "        VALUES (?, ?, CURRENT_TIMESTAMP, 'RUNNING')\n",
        "        \"\"\", [log_id, process_name])\n",
        "        return log_id\n",
        "\n",
        "    def log_process_end(self, log_id, records=0, status='SUCCESS', message=None):\n",
        "        \"\"\"Mencatat selesainya proses ETL\"\"\"\n",
        "        self.conn.execute(\"\"\"\n",
        "        UPDATE etl_log\n",
        "        SET end_time = CURRENT_TIMESTAMP,\n",
        "            records_processed = ?,\n",
        "            status = ?,\n",
        "            message = ?\n",
        "        WHERE log_id = ?\n",
        "        \"\"\", [records, status, message, log_id])\n",
        "\n",
        "    def initialize_warehouse(self):\n",
        "        \"\"\"Inisialisasi skema data warehouse jika belum ada\"\"\"\n",
        "        if self.initialized:\n",
        "            return\n",
        "\n",
        "        log_id = self.log_process_start(\"initialize_warehouse\")\n",
        "\n",
        "        try:\n",
        "            # Dimensi tanggal\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS dim_date (\n",
        "              date_key INTEGER PRIMARY KEY,\n",
        "              date DATE NOT NULL,\n",
        "              day INTEGER,\n",
        "              day_of_week INTEGER,\n",
        "              day_name VARCHAR,\n",
        "              month INTEGER,\n",
        "              month_name VARCHAR,\n",
        "              quarter INTEGER,\n",
        "              year INTEGER,\n",
        "              season VARCHAR\n",
        "            )\n",
        "            \"\"\")\n",
        "\n",
        "            # Dimensi produk\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS dim_product (\n",
        "              product_key INTEGER PRIMARY KEY,\n",
        "              product_id INTEGER NOT NULL,\n",
        "              product_name VARCHAR,\n",
        "              category VARCHAR,\n",
        "              subcategory VARCHAR,\n",
        "              unit_cost DECIMAL(10,2),\n",
        "              unit_price DECIMAL(10,2),\n",
        "              effective_date DATE,\n",
        "              expiration_date DATE,\n",
        "              current_flag BOOLEAN\n",
        "            )\n",
        "            \"\"\")\n",
        "\n",
        "            # Dimensi toko\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS dim_store (\n",
        "              store_key INTEGER PRIMARY KEY,\n",
        "              store_id INTEGER NOT NULL,\n",
        "              store_name VARCHAR,\n",
        "              city VARCHAR,\n",
        "              region VARCHAR,\n",
        "              store_type VARCHAR,\n",
        "              effective_date DATE,\n",
        "              expiration_date DATE,\n",
        "              current_flag BOOLEAN\n",
        "            )\n",
        "            \"\"\")\n",
        "\n",
        "            # Dimensi pelanggan\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS dim_customer (\n",
        "              customer_key INTEGER PRIMARY KEY,\n",
        "              customer_id INTEGER NOT NULL,\n",
        "              first_name VARCHAR,\n",
        "              last_name VARCHAR,\n",
        "              email VARCHAR,\n",
        "              city VARCHAR,\n",
        "              membership VARCHAR,\n",
        "              effective_date DATE,\n",
        "              expiration_date DATE,\n",
        "              current_flag BOOLEAN\n",
        "            )\n",
        "            \"\"\")\n",
        "\n",
        "            # Tabel fakta penjualan\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS fact_sales (\n",
        "              sales_key INTEGER PRIMARY KEY,\n",
        "              transaction_id VARCHAR,\n",
        "              date_key INTEGER,\n",
        "              product_key INTEGER,\n",
        "              store_key INTEGER,\n",
        "              customer_key INTEGER,\n",
        "              quantity INTEGER,\n",
        "              unit_price DECIMAL(10,2),\n",
        "              unit_cost DECIMAL(10,2),\n",
        "              discount_pct DECIMAL(5,2),\n",
        "              discount_amount DECIMAL(10,2),\n",
        "              sales_amount DECIMAL(10,2),\n",
        "              profit_amount DECIMAL(10,2),\n",
        "\n",
        "              FOREIGN KEY (date_key) REFERENCES dim_date(date_key),\n",
        "              FOREIGN KEY (product_key) REFERENCES dim_product(product_key),\n",
        "              FOREIGN KEY (store_key) REFERENCES dim_store(store_key),\n",
        "              FOREIGN KEY (customer_key) REFERENCES dim_customer(customer_key)\n",
        "            )\n",
        "            \"\"\")\n",
        "\n",
        "            # Berhasil inisialisasi\n",
        "            self.initialized = True\n",
        "            self.log_process_end(log_id, status='SUCCESS', message='Data warehouse schema initialized')\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_process_end(log_id, status='ERROR', message=str(e))\n",
        "            raise\n",
        "\n",
        "    def extract_all_sources(self):\n",
        "        \"\"\"Ekstrak data dari semua sumber\"\"\"\n",
        "        log_id = self.log_process_start(\"extract_all_sources\")\n",
        "\n",
        "        try:\n",
        "            # Bersihkan tabel staging\n",
        "            self.conn.execute(\"DROP TABLE IF EXISTS staging_products\")\n",
        "            self.conn.execute(\"DROP TABLE IF EXISTS staging_stores\")\n",
        "            self.conn.execute(\"DROP TABLE IF EXISTS staging_customers\")\n",
        "            self.conn.execute(\"DROP TABLE IF EXISTS staging_transactions\")\n",
        "\n",
        "            # Ekstrak data dari file CSV\n",
        "            self.conn.execute(\"CREATE TABLE staging_products AS SELECT * FROM read_csv_auto('data/products.csv')\")\n",
        "            self.conn.execute(\"CREATE TABLE staging_stores AS SELECT * FROM read_csv_auto('data/stores.csv')\")\n",
        "            self.conn.execute(\"CREATE TABLE staging_customers AS SELECT * FROM read_csv_auto('data/customers_dirty.csv')\")\n",
        "            self.conn.execute(\"CREATE TABLE staging_transactions AS SELECT * FROM read_csv_auto('data/transactions.csv')\")\n",
        "\n",
        "            # Hitung total jumlah catatan\n",
        "            total_records = 0\n",
        "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM staging_products\").fetchone()[0]\n",
        "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM staging_stores\").fetchone()[0]\n",
        "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM staging_customers\").fetchone()[0]\n",
        "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM staging_transactions\").fetchone()[0]\n",
        "\n",
        "            self.log_process_end(log_id, records=total_records, status='SUCCESS')\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_process_end(log_id, status='ERROR', message=str(e))\n",
        "            raise\n",
        "\n",
        "    def transform_data(self):\n",
        "        \"\"\"Transformasi data dari tabel staging\"\"\"\n",
        "        log_id = self.log_process_start(\"transform_data\")\n",
        "\n",
        "        try:\n",
        "            # 1. Transformasi dimensi tanggal\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE OR REPLACE TABLE dim_date AS\n",
        "            WITH date_range AS (\n",
        "              SELECT date::DATE as date\n",
        "              FROM generate_series('2022-01-01'::DATE, '2024-12-31'::DATE, INTERVAL '1 day') as date\n",
        "            )\n",
        "            SELECT\n",
        "              TO_VARCHAR(date, 'YYYYMMDD')::INTEGER AS date_key,\n",
        "              date,\n",
        "              EXTRACT(DAY FROM date) AS day,\n",
        "              EXTRACT(DOW FROM date) AS day_of_week,\n",
        "              dayname(date) AS day_name,\n",
        "              EXTRACT(MONTH FROM date) AS month,\n",
        "              monthname(date) AS month_name,\n",
        "              EXTRACT(QUARTER FROM date) AS quarter,\n",
        "              EXTRACT(YEAR FROM date) AS year,\n",
        "              CASE\n",
        "                WHEN EXTRACT(MONTH FROM date) BETWEEN 3 AND 5 THEN 'Spring'\n",
        "                WHEN EXTRACT(MONTH FROM date) BETWEEN 6 AND 8 THEN 'Summer'\n",
        "                WHEN EXTRACT(MONTH FROM date) BETWEEN 9 AND 11 THEN 'Fall'\n",
        "                ELSE 'Winter'\n",
        "              END AS season\n",
        "            FROM date_range\n",
        "            \"\"\")\n",
        "\n",
        "            # 2. Transformasi dimensi produk\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE OR REPLACE TABLE staging_dim_product AS\n",
        "            SELECT\n",
        "                product_id AS product_key,\n",
        "                product_id,\n",
        "                name AS product_name,\n",
        "                category,\n",
        "                subcategory,\n",
        "                base_cost AS unit_cost,\n",
        "                base_price AS unit_price,\n",
        "                '2022-01-01'::DATE AS effective_date,\n",
        "                NULL::DATE AS expiration_date,\n",
        "                TRUE AS current_flag\n",
        "            FROM staging_products\n",
        "            \"\"\")\n",
        "\n",
        "            # 3. Transformasi dimensi toko\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE OR REPLACE TABLE staging_dim_store AS\n",
        "            SELECT\n",
        "                store_id AS store_key,\n",
        "                store_id,\n",
        "                name AS store_name,\n",
        "                city,\n",
        "                region,\n",
        "                type AS store_type,\n",
        "                '2022-01-01'::DATE AS effective_date,\n",
        "                NULL::DATE AS expiration_date,\n",
        "                TRUE AS current_flag\n",
        "            FROM staging_stores\n",
        "            \"\"\")\n",
        "\n",
        "            # 4. Transformasi dimensi pelanggan dengan pembersihan data\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE OR REPLACE TABLE staging_dim_customer AS\n",
        "            WITH clean_customers AS (\n",
        "                SELECT\n",
        "                    customer_id,\n",
        "                    COALESCE(first_name, 'Unknown') AS first_name,\n",
        "                    COALESCE(last_name, 'Unknown') AS last_name,\n",
        "                    COALESCE(email, 'unknown@example.com') AS email,\n",
        "                    CASE\n",
        "                        WHEN city IS NULL THEN 'Unknown'\n",
        "                        ELSE INITCAP(LOWER(city)) -- Standarisasi kapitalisasi\n",
        "                    END AS city,\n",
        "                    membership,\n",
        "                    -- Ambil hanya baris pertama untuk email duplikat\n",
        "                    ROW_NUMBER() OVER (PARTITION BY email ORDER BY customer_id) AS rn\n",
        "                FROM staging_customers\n",
        "            )\n",
        "            SELECT\n",
        "                ROW_NUMBER() OVER (ORDER BY customer_id) AS customer_key,\n",
        "                customer_id,\n",
        "                first_name,\n",
        "                last_name,\n",
        "                email,\n",
        "                city,\n",
        "                membership,\n",
        "                '2022-01-01'::DATE AS effective_date,\n",
        "                NULL::DATE AS expiration_date,\n",
        "                TRUE AS current_flag\n",
        "            FROM clean_customers\n",
        "            WHERE rn = 1 -- Eliminasi duplikat\n",
        "            \"\"\")\n",
        "\n",
        "            # 5. Transformasi fakta penjualan\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE OR REPLACE TABLE staging_fact_sales AS\n",
        "            SELECT\n",
        "                ROW_NUMBER() OVER (ORDER BY transaction_id, product_id) AS sales_key,\n",
        "                transaction_id,\n",
        "                TO_VARCHAR(DATE(date), 'YYYYMMDD')::INTEGER AS date_key,\n",
        "                product_id AS product_key, -- Akan diganti nanti dengan JOIN\n",
        "                store_id AS store_key, -- Akan diganti nanti dengan JOIN\n",
        "                customer_id AS customer_key, -- Akan diganti nanti dengan JOIN\n",
        "                quantity,\n",
        "                unit_price,\n",
        "                unit_cost,\n",
        "                discount_pct,\n",
        "                discount_amount,\n",
        "                total_amount AS sales_amount,\n",
        "                profit AS profit_amount\n",
        "            FROM staging_transactions\n",
        "            \"\"\")\n",
        "\n",
        "            # Hitung jumlah catatan\n",
        "            total_records = 0\n",
        "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM dim_date\").fetchone()[0]\n",
        "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM staging_dim_product\").fetchone()[0]\n",
        "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM staging_dim_store\").fetchone()[0]\n",
        "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM staging_dim_customer\").fetchone()[0]\n",
        "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM staging_fact_sales\").fetchone()[0]\n",
        "\n",
        "            self.log_process_end(log_id, records=total_records, status='SUCCESS')\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_process_end(log_id, status='ERROR', message=str(e))\n",
        "            raise\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load data ke data warehouse\"\"\"\n",
        "        log_id = self.log_process_start(\"load_data\")\n",
        "\n",
        "        try:\n",
        "            # 1. Muat dimensi produk\n",
        "            self.conn.execute(\"DELETE FROM dim_product\")  # Bersihkan tabel sasaran\n",
        "            self.conn.execute(\"INSERT INTO dim_product SELECT * FROM staging_dim_product\")\n",
        "\n",
        "            # 2. Muat dimensi toko\n",
        "            self.conn.execute(\"DELETE FROM dim_store\")  # Bersihkan tabel sasaran\n",
        "            self.conn.execute(\"INSERT INTO dim_store SELECT * FROM staging_dim_store\")\n",
        "\n",
        "            # 3. Muat dimensi pelanggan\n",
        "            self.conn.execute(\"DELETE FROM dim_customer\")  # Bersihkan tabel sasaran\n",
        "            self.conn.execute(\"INSERT INTO dim_customer SELECT * FROM staging_dim_customer\")\n",
        "\n",
        "            # 4. Muat fakta penjualan dengan pemetaan kunci yang benar\n",
        "            self.conn.execute(\"DELETE FROM fact_sales\")  # Bersihkan tabel sasaran\n",
        "            self.conn.execute(\"\"\"\n",
        "            INSERT INTO fact_sales\n",
        "            SELECT\n",
        "                f.sales_key,\n",
        "                f.transaction_id,\n",
        "                f.date_key,\n",
        "                p.product_key,\n",
        "                s.store_key,\n",
        "                c.customer_key,\n",
        "                f.quantity,\n",
        "                f.unit_price,\n",
        "                f.unit_cost,\n",
        "                f.discount_pct,\n",
        "                f.discount_amount,\n",
        "                f.sales_amount,\n",
        "                f.profit_amount\n",
        "            FROM staging_fact_sales f\n",
        "            JOIN dim_product p ON f.product_key = p.product_id\n",
        "            JOIN dim_store s ON f.store_key = s.store_id\n",
        "            JOIN dim_customer c ON f.customer_key = c.customer_id\n",
        "            \"\"\")\n",
        "\n",
        "            # Menghitung jumlah baris yang dimuat\n",
        "            product_count = self.conn.execute(\"SELECT COUNT(*) FROM dim_product\").fetchone()[0]\n",
        "            store_count = self.conn.execute(\"SELECT COUNT(*) FROM dim_store\").fetchone()[0]\n",
        "            customer_count = self.conn.execute(\"SELECT COUNT(*) FROM dim_customer\").fetchone()[0]\n",
        "            sales_count = self.conn.execute(\"SELECT COUNT(*) FROM fact_sales\").fetchone()[0]\n",
        "\n",
        "            total_records = product_count + store_count + customer_count + sales_count\n",
        "\n",
        "            self.log_process_end(log_id, records=total_records, status='SUCCESS',\n",
        "                                message=f'Loaded {product_count} products, {store_count} stores, '\n",
        "                                        f'{customer_count} customers, {sales_count} sales')\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_process_end(log_id, status='ERROR', message=str(e))\n",
        "            raise\n",
        "\n",
        "    def run_full_pipeline(self):\n",
        "        \"\"\"Jalankan seluruh pipeline ETL\"\"\"\n",
        "        print(\"Menjalankan ETL Pipeline lengkap...\")\n",
        "\n",
        "        start_time = datetime.now()\n",
        "\n",
        "        try:\n",
        "            # 1. Inisialisasi warehouse\n",
        "            self.initialize_warehouse()\n",
        "            print(\"âœ“ Data warehouse diinisialisasi\")\n",
        "\n",
        "            # 2. Ekstrak data\n",
        "            self.extract_all_sources()\n",
        "            print(\"âœ“ Data diekstrak dari semua sumber\")\n",
        "\n",
        "            # 3. Transform data\n",
        "            self.transform_data()\n",
        "            print(\"âœ“ Data ditransformasi\")\n",
        "\n",
        "            # 4. Load data\n",
        "            self.load_data()\n",
        "            print(\"âœ“ Data dimuat ke data warehouse\")\n",
        "\n",
        "            end_time = datetime.now()\n",
        "            duration = (end_time - start_time).total_seconds()\n",
        "\n",
        "            print(f\"\\nPipeline ETL selesai dalam {duration:.2f} detik\")\n",
        "\n",
        "            # Menampilkan statistik\n",
        "            stats = self.conn.execute(\"\"\"\n",
        "                SELECT\n",
        "                    (SELECT COUNT(*) FROM dim_date) as date_count,\n",
        "                    (SELECT COUNT(*) FROM dim_product) as product_count,\n",
        "                    (SELECT COUNT(*) FROM dim_store) as store_count,\n",
        "                    (SELECT COUNT(*) FROM dim_customer) as customer_count,\n",
        "                    (SELECT COUNT(*) FROM fact_sales) as sales_count\n",
        "            \"\"\").fetchone()\n",
        "\n",
        "            print(\"\\nStatistik Data Warehouse:\")\n",
        "            print(f\"âœ“ Dimensi Tanggal: {stats[0]} baris\")\n",
        "            print(f\"âœ“ Dimensi Produk: {stats[1]} baris\")\n",
        "            print(f\"âœ“ Dimensi Toko: {stats[2]} baris\")\n",
        "            print(f\"âœ“ Dimensi Pelanggan: {stats[3]} baris\")\n",
        "            print(f\"âœ“ Fakta Penjualan: {stats[4]} baris\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR: Pipeline ETL gagal: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def get_etl_log(self, limit=10):\n",
        "        \"\"\"Menampilkan log ETL terakhir\"\"\"\n",
        "        return self.conn.execute(f\"\"\"\n",
        "            SELECT\n",
        "                log_id,\n",
        "                process_name,\n",
        "                start_time,\n",
        "                end_time,\n",
        "                EXTRACT(EPOCH FROM (end_time - start_time)) as duration_seconds,\n",
        "                records_processed,\n",
        "                status,\n",
        "                message\n",
        "            FROM etl_log\n",
        "            ORDER BY log_id DESC\n",
        "            LIMIT {limit}\n",
        "        \"\"\").fetchdf()\n",
        "\n",
        "    def __del__(self):\n",
        "        \"\"\"Menutup koneksi saat objek dihapus\"\"\"\n",
        "        try:\n",
        "            if hasattr(self, 'conn'):\n",
        "                self.conn.close()\n",
        "                print(\"Koneksi DuckDB ditutup.\")\n",
        "        except:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Csb8ob1arCsf"
      },
      "source": [
        "Jalankan pipeline otomatis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqxMlng3rCsf"
      },
      "outputs": [],
      "source": [
        "pipeline = ETLPipeline()\n",
        "pipeline.run_full_pipeline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK-l1dfWrCsf"
      },
      "source": [
        "Lihat log ETL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4pf9v6trCsf"
      },
      "outputs": [],
      "source": [
        "pipeline.get_etl_log()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPIutrbPrCsf"
      },
      "source": [
        "## 11. Kesimpulan\n",
        "\n",
        "Dalam tutorial ini, kita telah mempelajari:\n",
        "\n",
        "1. **Konsep dasar data warehouse** - OLTP vs OLAP, desain dimensional\n",
        "2. **Implementasi Schema** - Star Schema, Snowflake Schema, dan Fact Constellation\n",
        "3. **Proses ETL** - Extract, Transform, Load dengan berbagai pendekatan\n",
        "   - Transformasi menggunakan pandas (Python)\n",
        "   - Transformasi menggunakan SQL di DuckDB\n",
        "4. **SCD Type 2** - Menangani perubahan historis pada dimensi\n",
        "5. **ETL Inkremental** - Memproses hanya data baru\n",
        "6. **Otomatisasi Pipeline** - Membuat class untuk mengelola seluruh proses\n",
        "\n",
        "Beberapa _best practice_ yang telah kita terapkan:\n",
        "\n",
        "1. **Pembersihan data** - Menangani data yang hilang, duplikat, dan inkonsistensi\n",
        "2. **Pelacakan historis** - Menggunakan SCD Type 2 untuk _tracking_ perubahan\n",
        "3. **Pemisahan tanggung jawab** - Memisahkan ekstraksi, transformasi, dan loading\n",
        "4. **Logging** - Mencatat semua proses ETL\n",
        "5. **Error handling** - Menangani kesalahan dengan baik\n",
        "6. **Dokumentasi** - Menjelaskan setiap langkah proses"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}