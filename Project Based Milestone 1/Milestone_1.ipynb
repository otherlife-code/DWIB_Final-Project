{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEPyM7LIrCsH"
      },
      "source": [
        "# Tutorial Pemodelan Data dan ETL dengan DuckDB\n",
        "\n",
        "## Pengantar\n",
        "\n",
        "Dalam tutorial ini, kita akan mempelajari cara implementasi pipeline ETL (Extract, Transform, Load) untuk data warehouse menggunakan DuckDB. Kita akan fokus pada pemodelan dimensi dan proses ETL yang realistis."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GIT"
      ],
      "metadata": {
        "id": "4KAUvssCugDT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "makan malam"
      ],
      "metadata": {
        "id": "vdRu2F1gvBeR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cey-SOtIrCsM"
      },
      "source": [
        "## 1.Persiapan DuckDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63pVp3PprCsN"
      },
      "source": [
        "Instal library yang diperlukan<br>\n",
        "pip install duckdb pandas numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKpZsz5arCsN"
      },
      "source": [
        "Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZfnhQnvbrCsO"
      },
      "outputs": [],
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gKdfv5orCsP"
      },
      "source": [
        "Koneksi ke DuckDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i6TyFCERrCsQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb422d27-7654-4bef-a053-1574f8d51348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Terhubung ke DuckDB!\n"
          ]
        }
      ],
      "source": [
        "conn = duckdb.connect('retail_dw.db')\n",
        "print(\"Terhubung ke DuckDB!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Table Fact_Transactions {\n",
        "  Transaction_ID INT [primary key]\n",
        "  CLIENTNUM INT [ref: > Dim_Customer.CLIENTNUM]\n",
        "  Card_ID INT [ref: > Dim_Card.Card_ID]\n",
        "  Demographic_ID INT [ref: > Dim_Demographics.Demographic_ID]\n",
        "  Time_ID INT [ref: > Dim_Time.Time_ID]\n",
        "  Credit_Limit FLOAT\n",
        "  Total_Revolving_Bal INT\n",
        "  Avg_Open_To_Buy FLOAT\n",
        "  Total_Amt_Chng_Q4_Q1 FLOAT\n",
        "  Total_Trans_Amt INT\n",
        "  Total_Trans_Ct INT\n",
        "  Total_Ct_Chng_Q4_Q1 FLOAT\n",
        "  Avg_Utilization_Ratio FLOAT\n",
        "}\n",
        "\n",
        "Table Dim_Customer {\n",
        "  CLIENTNUM INT [primary key]\n",
        "  Attrition_Flag VARCHAR\n",
        "  Customer_Age INT\n",
        "  Months_on_book INT\n",
        "}\n",
        "\n",
        "Table Dim_Card {\n",
        "  Card_ID INT [primary key]\n",
        "  Card_Category VARCHAR\n",
        "}\n",
        "\n",
        "Table Dim_Demographics {\n",
        "  Demographic_ID INT [primary key]\n",
        "  Gender VARCHAR\n",
        "  Dependent_count INT\n",
        "  Education_Level VARCHAR\n",
        "  Marital_Status VARCHAR\n",
        "  Income_Category VARCHAR\n",
        "}\n",
        "\n",
        "Table Dim_Time {\n",
        "  Time_ID INT [primary key]\n",
        "  Months_Inactive_12_mon INT\n",
        "  Contacts_Count_12_mon INT\n",
        "}"
      ],
      "metadata": {
        "id": "OpqgUh2t40D0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHFdy0Z-rCsQ"
      },
      "source": [
        "## 2. Konsep Dasar Pemodelan Data Warehouse\n",
        "\n",
        "### OLTP vs OLAP\n",
        "\n",
        "| Aspek | OLTP | OLAP |\n",
        "|--------|------|------|\n",
        "| Tujuan | Pemrosesan transaksi | Analisis data |\n",
        "| Desain | Ternormalisasi | Denormalisasi |\n",
        "| Kueri | Sederhana, fokus pada catatan spesifik | Kompleks, melibatkan agregasi dan join |\n",
        "| Performa | Dioptimalkan untuk transaksi (tulis) | Dioptimalkan untuk query (baca) |\n",
        "| Data | Data saat ini | Data historis |\n",
        "| Ukuran | Lebih kecil | Jauh lebih besar |\n",
        "\n",
        "### Skema Pemodelan Dimensional\n",
        "\n",
        "**1. Star Schema (Skema Bintang)**\n",
        "- Tabel fakta pusat dengan pengukuran bisnis\n",
        "- Tabel dimensi terhubung langsung ke tabel fakta\n",
        "\n",
        "**2. Snowflake Schema (Skema Kepingan Salju)**\n",
        "- Perluasan dari skema bintang\n",
        "- Dimensi-dimensi dinormalisasi lebih lanjut\n",
        "\n",
        "**3. Fact Constellation (Konstelasi Fakta)**\n",
        "- Beberapa tabel fakta berbagi tabel dimensi\n",
        "- Juga dikenal sebagai Galaxy Schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtQXVELLrCsR"
      },
      "source": [
        "## 3. Persiapan Data Sumber<br>\n",
        "<br>\n",
        "Dalam situasi dunia nyata, data berasal dari berbagai sumber. Mari simulasikan dengan beberapa dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY6d5nVKrCsR"
      },
      "source": [
        "Fungsi untuk mengunduh dataset contoh (lebih realistis dibanding data random)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqybqR-QzRkb",
        "outputId": "a2988478-9dea-489a-d765-d3ac5611aa36"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "ClCVIYd80kQY",
        "outputId": "5dfb48e1-7d7c-4f87-be53-76cd0a1091f2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0c23c4e8-6d79-4e62-93bf-1375eca8c2db\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0c23c4e8-6d79-4e62-93bf-1375eca8c2db\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"laurenzjuan\",\"key\":\"909ab406ffdf0cd705ff9ec2d5fbb6a0\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "cUpHiM-52BPp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unduh Dataset**"
      ],
      "metadata": {
        "id": "0sV9_Guv2OBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d sakshigoyal7/credit-card-customers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVUlWXSo2MWQ",
        "outputId": "7f0a2ad1-9a43-4ab9-934f-35808f6455f6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.7.4.2 / client 1.6.17)\n",
            "Dataset URL: https://www.kaggle.com/datasets/sakshigoyal7/credit-card-customers\n",
            "License(s): CC0-1.0\n",
            "Downloading credit-card-customers.zip to /content\n",
            "  0% 0.00/379k [00:00<?, ?B/s]\n",
            "100% 379k/379k [00:00<00:00, 23.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip credit-card-customers.zip\n"
      ],
      "metadata": {
        "id": "gqsuCQdj5N0h",
        "outputId": "be074a54-3308-4806-ff9f-6060fe25b56a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  credit-card-customers.zip\n",
            "  inflating: BankChurners.csv        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"BankChurners.csv\")  # Gantilah dengan nama file yang sesuai\n"
      ],
      "metadata": {
        "id": "ApF4c3PI5Rzp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "PO06FwYJ5YQi",
        "outputId": "a1f8f232-3c13-454d-99e7-f7720fc06d2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CLIENTNUM     Attrition_Flag  Customer_Age Gender  Dependent_count  \\\n",
              "0  768805383  Existing Customer            45      M                3   \n",
              "1  818770008  Existing Customer            49      F                5   \n",
              "2  713982108  Existing Customer            51      M                3   \n",
              "3  769911858  Existing Customer            40      F                4   \n",
              "4  709106358  Existing Customer            40      M                3   \n",
              "\n",
              "  Education_Level Marital_Status Income_Category Card_Category  \\\n",
              "0     High School        Married     $60K - $80K          Blue   \n",
              "1        Graduate         Single  Less than $40K          Blue   \n",
              "2        Graduate        Married    $80K - $120K          Blue   \n",
              "3     High School        Unknown  Less than $40K          Blue   \n",
              "4      Uneducated        Married     $60K - $80K          Blue   \n",
              "\n",
              "   Months_on_book  ...  Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  \\\n",
              "0              39  ...       12691.0                  777          11914.0   \n",
              "1              44  ...        8256.0                  864           7392.0   \n",
              "2              36  ...        3418.0                    0           3418.0   \n",
              "3              34  ...        3313.0                 2517            796.0   \n",
              "4              21  ...        4716.0                    0           4716.0   \n",
              "\n",
              "   Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  \\\n",
              "0                 1.335             1144              42                1.625   \n",
              "1                 1.541             1291              33                3.714   \n",
              "2                 2.594             1887              20                2.333   \n",
              "3                 1.405             1171              20                2.333   \n",
              "4                 2.175              816              28                2.500   \n",
              "\n",
              "   Avg_Utilization_Ratio  \\\n",
              "0                  0.061   \n",
              "1                  0.105   \n",
              "2                  0.000   \n",
              "3                  0.760   \n",
              "4                  0.000   \n",
              "\n",
              "   Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1  \\\n",
              "0                                           0.000093                                                                                    \n",
              "1                                           0.000057                                                                                    \n",
              "2                                           0.000021                                                                                    \n",
              "3                                           0.000134                                                                                    \n",
              "4                                           0.000022                                                                                    \n",
              "\n",
              "   Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2  \n",
              "0                                            0.99991                                                                                   \n",
              "1                                            0.99994                                                                                   \n",
              "2                                            0.99998                                                                                   \n",
              "3                                            0.99987                                                                                   \n",
              "4                                            0.99998                                                                                   \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1307274-f724-4717-ae86-345993cbbb2a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CLIENTNUM</th>\n",
              "      <th>Attrition_Flag</th>\n",
              "      <th>Customer_Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Dependent_count</th>\n",
              "      <th>Education_Level</th>\n",
              "      <th>Marital_Status</th>\n",
              "      <th>Income_Category</th>\n",
              "      <th>Card_Category</th>\n",
              "      <th>Months_on_book</th>\n",
              "      <th>...</th>\n",
              "      <th>Credit_Limit</th>\n",
              "      <th>Total_Revolving_Bal</th>\n",
              "      <th>Avg_Open_To_Buy</th>\n",
              "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
              "      <th>Total_Trans_Amt</th>\n",
              "      <th>Total_Trans_Ct</th>\n",
              "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
              "      <th>Avg_Utilization_Ratio</th>\n",
              "      <th>Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1</th>\n",
              "      <th>Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>768805383</td>\n",
              "      <td>Existing Customer</td>\n",
              "      <td>45</td>\n",
              "      <td>M</td>\n",
              "      <td>3</td>\n",
              "      <td>High School</td>\n",
              "      <td>Married</td>\n",
              "      <td>$60K - $80K</td>\n",
              "      <td>Blue</td>\n",
              "      <td>39</td>\n",
              "      <td>...</td>\n",
              "      <td>12691.0</td>\n",
              "      <td>777</td>\n",
              "      <td>11914.0</td>\n",
              "      <td>1.335</td>\n",
              "      <td>1144</td>\n",
              "      <td>42</td>\n",
              "      <td>1.625</td>\n",
              "      <td>0.061</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.99991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>818770008</td>\n",
              "      <td>Existing Customer</td>\n",
              "      <td>49</td>\n",
              "      <td>F</td>\n",
              "      <td>5</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Single</td>\n",
              "      <td>Less than $40K</td>\n",
              "      <td>Blue</td>\n",
              "      <td>44</td>\n",
              "      <td>...</td>\n",
              "      <td>8256.0</td>\n",
              "      <td>864</td>\n",
              "      <td>7392.0</td>\n",
              "      <td>1.541</td>\n",
              "      <td>1291</td>\n",
              "      <td>33</td>\n",
              "      <td>3.714</td>\n",
              "      <td>0.105</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.99994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>713982108</td>\n",
              "      <td>Existing Customer</td>\n",
              "      <td>51</td>\n",
              "      <td>M</td>\n",
              "      <td>3</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Married</td>\n",
              "      <td>$80K - $120K</td>\n",
              "      <td>Blue</td>\n",
              "      <td>36</td>\n",
              "      <td>...</td>\n",
              "      <td>3418.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3418.0</td>\n",
              "      <td>2.594</td>\n",
              "      <td>1887</td>\n",
              "      <td>20</td>\n",
              "      <td>2.333</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.99998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>769911858</td>\n",
              "      <td>Existing Customer</td>\n",
              "      <td>40</td>\n",
              "      <td>F</td>\n",
              "      <td>4</td>\n",
              "      <td>High School</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Less than $40K</td>\n",
              "      <td>Blue</td>\n",
              "      <td>34</td>\n",
              "      <td>...</td>\n",
              "      <td>3313.0</td>\n",
              "      <td>2517</td>\n",
              "      <td>796.0</td>\n",
              "      <td>1.405</td>\n",
              "      <td>1171</td>\n",
              "      <td>20</td>\n",
              "      <td>2.333</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.000134</td>\n",
              "      <td>0.99987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>709106358</td>\n",
              "      <td>Existing Customer</td>\n",
              "      <td>40</td>\n",
              "      <td>M</td>\n",
              "      <td>3</td>\n",
              "      <td>Uneducated</td>\n",
              "      <td>Married</td>\n",
              "      <td>$60K - $80K</td>\n",
              "      <td>Blue</td>\n",
              "      <td>21</td>\n",
              "      <td>...</td>\n",
              "      <td>4716.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4716.0</td>\n",
              "      <td>2.175</td>\n",
              "      <td>816</td>\n",
              "      <td>28</td>\n",
              "      <td>2.500</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.99998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1307274-f724-4717-ae86-345993cbbb2a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a1307274-f724-4717-ae86-345993cbbb2a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a1307274-f724-4717-ae86-345993cbbb2a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ec7bce24-c246-4120-b48a-aac448c55db9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ec7bce24-c246-4120-b48a-aac448c55db9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ec7bce24-c246-4120-b48a-aac448c55db9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpOF_Y6wrCsR"
      },
      "outputs": [],
      "source": [
        "def download_sample_data():\n",
        "    \"\"\"Mengunduh dan menyiapkan dataset sampel\"\"\"\n",
        "\n",
        "    # Buat folder data jika belum ada\n",
        "    if not os.path.exists('data'):\n",
        "        os.makedirs('data')\n",
        "\n",
        "    # Data transaksi penjualan (simulasi dari CSV ekspor)\n",
        "    # Membuat data contoh yang realistis\n",
        "\n",
        "    # 1. Data produk\n",
        "    products = pd.DataFrame({\n",
        "        'product_id': range(1, 51),\n",
        "        'name': [f'Product-{i}' for i in range(1, 51)],\n",
        "        'category': np.random.choice(['Electronics', 'Clothing', 'Home', 'Books', 'Food'], 50),\n",
        "        'subcategory': np.random.choice(['Smartphones', 'Laptops', 'T-shirts', 'Pants', 'Kitchen',\n",
        "                                       'Bedroom', 'Fiction', 'Non-fiction', 'Snacks', 'Beverages'], 50),\n",
        "        'base_cost': np.random.uniform(5, 200, 50).round(2),\n",
        "        'base_price': np.random.uniform(10, 300, 50).round(2)\n",
        "    })\n",
        "\n",
        "    # 2. Data toko\n",
        "    stores = pd.DataFrame({\n",
        "        'store_id': range(1, 21),\n",
        "        'name': [f'Store-{i}' for i in range(1, 21)],\n",
        "        'city': np.random.choice(['Jakarta', 'Bandung', 'Surabaya', 'Yogyakarta', 'Medan'], 20),\n",
        "        'region': np.random.choice(['Jawa', 'Sumatera', 'Kalimantan', 'Sulawesi'], 20),\n",
        "        'type': np.random.choice(['Mall', 'Street', 'Standalone'], 20)\n",
        "    })\n",
        "\n",
        "    # 3. Data pelanggan\n",
        "    customers = pd.DataFrame({\n",
        "        'customer_id': range(1, 201),\n",
        "        'first_name': [f'First-{i}' for i in range(1, 201)],\n",
        "        'last_name': [f'Last-{i}' for i in range(1, 201)],\n",
        "        'email': [f'customer{i}@example.com' for i in range(1, 201)],\n",
        "        'city': np.random.choice(['Jakarta', 'Bandung', 'Surabaya', 'Yogyakarta', 'Medan',\n",
        "                                 'Makassar', 'Palembang', 'Semarang'], 200),\n",
        "        'membership': np.random.choice(['Silver', 'Gold', 'Platinum', 'Regular'], 200)\n",
        "    })\n",
        "\n",
        "    # 4. Generate transaksi\n",
        "    # Simulasi data dari point of sale system\n",
        "    num_transactions = 5000\n",
        "    transactions = []\n",
        "\n",
        "    start_date = datetime(2022, 1, 1)\n",
        "    end_date = datetime(2023, 12, 31)\n",
        "    dates = [start_date + timedelta(days=np.random.randint(0, (end_date-start_date).days))\n",
        "             for _ in range(num_transactions)]\n",
        "\n",
        "    for i in range(num_transactions):\n",
        "        tx_date = dates[i]\n",
        "        store_id = np.random.choice(stores['store_id'])\n",
        "        customer_id = np.random.choice(customers['customer_id'])\n",
        "\n",
        "        # Setiap transaksi bisa punya beberapa item\n",
        "        items_count = np.random.randint(1, 5)\n",
        "\n",
        "        for j in range(items_count):\n",
        "            product_id = np.random.choice(products['product_id'])\n",
        "            product_info = products[products['product_id'] == product_id].iloc[0]\n",
        "\n",
        "            # Harga bisa bervariasi dari waktu ke waktu\n",
        "            price_variance = np.random.uniform(0.9, 1.1)\n",
        "            price = round(product_info['base_price'] * price_variance, 2)\n",
        "\n",
        "            cost_variance = np.random.uniform(0.95, 1.05)\n",
        "            cost = round(product_info['base_cost'] * cost_variance, 2)\n",
        "\n",
        "            quantity = np.random.randint(1, 6)\n",
        "\n",
        "            # Diskon kadang diberikan\n",
        "            discount_pct = 0\n",
        "            if np.random.random() < 0.3:  # 30% transaksi mendapat diskon\n",
        "                discount_pct = np.random.choice([5, 10, 15, 20, 25, 50]) / 100\n",
        "\n",
        "            discount_amount = round(price * quantity * discount_pct, 2)\n",
        "            total = round(price * quantity - discount_amount, 2)\n",
        "            profit = round(total - (cost * quantity), 2)\n",
        "\n",
        "            transactions.append({\n",
        "                'transaction_id': f'TX-{i+1}',\n",
        "                'date': tx_date.strftime('%Y-%m-%d'),\n",
        "                'store_id': store_id,\n",
        "                'customer_id': customer_id,\n",
        "                'product_id': product_id,\n",
        "                'quantity': quantity,\n",
        "                'unit_price': price,\n",
        "                'unit_cost': cost,\n",
        "                'discount_pct': discount_pct,\n",
        "                'discount_amount': discount_amount,\n",
        "                'total_amount': total,\n",
        "                'profit': profit\n",
        "            })\n",
        "\n",
        "    # Simpan semua data ke CSV (simulasi data dari berbagai sumber)\n",
        "    products.to_csv('data/products.csv', index=False)\n",
        "    stores.to_csv('data/stores.csv', index=False)\n",
        "    customers.to_csv('data/customers.csv', index=False)\n",
        "\n",
        "    tx_df = pd.DataFrame(transactions)\n",
        "    tx_df.to_csv('data/transactions.csv', index=False)\n",
        "\n",
        "    # Buat data yang \"kotor\" dengan sengaja (seperti di dunia nyata)\n",
        "    # Salin data pelanggan, tapi dengan beberapa kesalahan\n",
        "    customers_dirty = customers.copy()\n",
        "    # Ubah beberapa nilai\n",
        "    for i in range(20):\n",
        "        idx = np.random.randint(0, len(customers_dirty))\n",
        "        if np.random.random() < 0.5:\n",
        "            customers_dirty.loc[idx, 'city'] = customers_dirty.loc[idx, 'city'].upper()\n",
        "        else:\n",
        "            customers_dirty.loc[idx, 'city'] = customers_dirty.loc[idx, 'city'].lower()\n",
        "\n",
        "    # Tambahkan beberapa nilai duplikat dengan ID berbeda\n",
        "    duplicates = customers.sample(10).copy()\n",
        "    duplicates['customer_id'] = range(201, 211)\n",
        "    customers_dirty = pd.concat([customers_dirty, duplicates])\n",
        "\n",
        "    # Tambahkan nilai kosong\n",
        "    for i in range(15):\n",
        "        idx = np.random.randint(0, len(customers_dirty))\n",
        "        col = np.random.choice(['first_name', 'last_name', 'email', 'city'])\n",
        "        customers_dirty.loc[idx, col] = np.nan\n",
        "\n",
        "    customers_dirty.to_csv('data/customers_dirty.csv', index=False)\n",
        "\n",
        "    print(f\"Data sampel berhasil dibuat:\")\n",
        "    print(f\"- {len(products)} produk\")\n",
        "    print(f\"- {len(stores)} toko\")\n",
        "    print(f\"- {len(customers)} pelanggan\")\n",
        "    print(f\"- {len(tx_df)} transaksi\")\n",
        "    print(f\"- {len(customers_dirty)} pelanggan (dengan data kotor)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFB6v9kErCsS"
      },
      "source": [
        "Unduh/Buat data sampel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AWn_ifxrCsS"
      },
      "outputs": [],
      "source": [
        "download_sample_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad4Bx0uMrCsS"
      },
      "source": [
        "## 4. Perancangan Model Data Warehouse<br>\n",
        "<br>\n",
        "Kita akan menerapkan model Star Schema untuk data warehouse retail kita:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I55yHwirrCsT"
      },
      "outputs": [],
      "source": [
        "def create_data_warehouse_schema():\n",
        "    \"\"\"Membuat skema data warehouse (dimensi & tabel fakta)\"\"\"\n",
        "\n",
        "    # Drop dependent tables first to avoid dependency errors\n",
        "    try:\n",
        "        conn.execute(\"DROP TABLE IF EXISTS fact_sales;\")\n",
        "        conn.execute(\"DROP TABLE IF EXISTS fact_inventory;\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # 1. Buat dimensi tanggal terlebih dahulu - fixed for DuckDB\n",
        "    conn.execute(\"\"\"\n",
        "    -- Dimensi Tanggal\n",
        "    CREATE OR REPLACE TABLE dim_date AS\n",
        "    WITH date_range AS (\n",
        "      SELECT unnest(generate_series('2022-01-01'::DATE, '2023-12-31'::DATE, INTERVAL '1 day')) as date\n",
        "    )\n",
        "    SELECT\n",
        "      (EXTRACT(YEAR FROM date) * 10000 + EXTRACT(MONTH FROM date) * 100 + EXTRACT(DAY FROM date))::INTEGER AS date_key,\n",
        "      date,\n",
        "      EXTRACT(DAY FROM date) AS day,\n",
        "      EXTRACT(MONTH FROM date) AS month,\n",
        "      strftime(date, '%B') AS month_name,\n",
        "      EXTRACT(QUARTER FROM date) AS quarter,\n",
        "      EXTRACT(YEAR FROM date) AS year,\n",
        "      EXTRACT(DOW FROM date) AS day_of_week,\n",
        "      strftime(date, '%A') AS day_name,\n",
        "      CASE\n",
        "        WHEN EXTRACT(MONTH FROM date) BETWEEN 3 AND 5 THEN 'Spring'\n",
        "        WHEN EXTRACT(MONTH FROM date) BETWEEN 6 AND 8 THEN 'Summer'\n",
        "        WHEN EXTRACT(MONTH FROM date) BETWEEN 9 AND 11 THEN 'Fall'\n",
        "        ELSE 'Winter'\n",
        "      END AS season\n",
        "    FROM date_range;\n",
        "    \"\"\")\n",
        "\n",
        "    # Add primary key to dim_date table\n",
        "    conn.execute(\"\"\"\n",
        "    ALTER TABLE dim_date ADD PRIMARY KEY (date_key);\n",
        "    \"\"\")\n",
        "\n",
        "    # 2. Buat tabel dimensi lainnya (kosong)\n",
        "    conn.execute(\"\"\"\n",
        "    -- Dimensi Produk\n",
        "    CREATE OR REPLACE TABLE dim_product (\n",
        "      product_key INTEGER PRIMARY KEY,\n",
        "      product_id INTEGER NOT NULL,\n",
        "      product_name VARCHAR,\n",
        "      category VARCHAR,\n",
        "      subcategory VARCHAR,\n",
        "      unit_cost DECIMAL(10,2),\n",
        "      unit_price DECIMAL(10,2),\n",
        "      effective_date DATE,\n",
        "      expiration_date DATE,\n",
        "      current_flag BOOLEAN\n",
        "    );\n",
        "\n",
        "    -- Dimensi Toko\n",
        "    CREATE OR REPLACE TABLE dim_store (\n",
        "      store_key INTEGER PRIMARY KEY,\n",
        "      store_id INTEGER NOT NULL,\n",
        "      store_name VARCHAR,\n",
        "      city VARCHAR,\n",
        "      region VARCHAR,\n",
        "      store_type VARCHAR,\n",
        "      effective_date DATE,\n",
        "      expiration_date DATE,\n",
        "      current_flag BOOLEAN\n",
        "    );\n",
        "\n",
        "    -- Dimensi Pelanggan\n",
        "    CREATE OR REPLACE TABLE dim_customer (\n",
        "      customer_key INTEGER PRIMARY KEY,\n",
        "      customer_id INTEGER NOT NULL,\n",
        "      first_name VARCHAR,\n",
        "      last_name VARCHAR,\n",
        "      email VARCHAR,\n",
        "      city VARCHAR,\n",
        "      membership VARCHAR,\n",
        "      effective_date DATE,\n",
        "      expiration_date DATE,\n",
        "      current_flag BOOLEAN\n",
        "    );\n",
        "\n",
        "    -- Tabel Fakta Penjualan\n",
        "    CREATE OR REPLACE TABLE fact_sales (\n",
        "      sales_key INTEGER PRIMARY KEY,\n",
        "      transaction_id VARCHAR,\n",
        "      date_key INTEGER,\n",
        "      product_key INTEGER,\n",
        "      store_key INTEGER,\n",
        "      customer_key INTEGER,\n",
        "      quantity INTEGER,\n",
        "      unit_price DECIMAL(10,2),\n",
        "      unit_cost DECIMAL(10,2),\n",
        "      discount_pct DECIMAL(5,2),\n",
        "      discount_amount DECIMAL(10,2),\n",
        "      sales_amount DECIMAL(10,2),\n",
        "      profit_amount DECIMAL(10,2),\n",
        "\n",
        "      FOREIGN KEY (date_key) REFERENCES dim_date(date_key),\n",
        "      FOREIGN KEY (product_key) REFERENCES dim_product(product_key),\n",
        "      FOREIGN KEY (store_key) REFERENCES dim_store(store_key),\n",
        "      FOREIGN KEY (customer_key) REFERENCES dim_customer(customer_key)\n",
        "    );\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"Skema data warehouse berhasil dibuat!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-fmyTgXrCsT"
      },
      "source": [
        "Buat skema data warehouse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKj_6Hi6rCsT"
      },
      "outputs": [],
      "source": [
        "create_data_warehouse_schema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg79lAw4rCsT"
      },
      "source": [
        "## 5. Proses ETL (Extract, Transform, Load)<br>\n",
        "<br>\n",
        "Sekarang kita implementasikan proses ETL yang komprehensif:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF9qTfLPrCsT"
      },
      "source": [
        "### 5.1 Extract - Mengambil Data dari Sumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xgyWX1irCsU"
      },
      "outputs": [],
      "source": [
        "def extract_source_data():\n",
        "    \"\"\"Ekstrak data dari berbagai sumber\"\"\"\n",
        "\n",
        "    # Baca data dari file CSV\n",
        "    products_df = pd.read_csv('data/products.csv')\n",
        "    stores_df = pd.read_csv('data/stores.csv')\n",
        "    customers_df = pd.read_csv('data/customers_dirty.csv')  # Sengaja menggunakan data kotor\n",
        "    transactions_df = pd.read_csv('data/transactions.csv')\n",
        "\n",
        "    print(f\"Data berhasil diekstrak:\")\n",
        "    print(f\"- Produk: {len(products_df)} baris\")\n",
        "    print(f\"- Toko: {len(stores_df)} baris\")\n",
        "    print(f\"- Pelanggan: {len(customers_df)} baris\")\n",
        "    print(f\"- Transaksi: {len(transactions_df)} baris\")\n",
        "\n",
        "    return products_df, stores_df, customers_df, transactions_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1fo4GpWrCsU"
      },
      "source": [
        "Ekstrak data dari sumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZn__EqIrCsU"
      },
      "outputs": [],
      "source": [
        "products_df, stores_df, customers_df, transactions_df = extract_source_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPS3vMtHrCsU"
      },
      "source": [
        "### 5.2 Transform - Membersihkan dan Mengubah Data<br>\n",
        "<br>\n",
        "Kita implementasikan dua pendekatan transformasi:<br>\n",
        "1. Menggunakan pandas (Python)<br>\n",
        "2. Menggunakan SQL di DuckDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXowbyPGrCsU"
      },
      "source": [
        "In[8]:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxxGCBcyrCsU"
      },
      "outputs": [],
      "source": [
        "def transform_with_pandas():\n",
        "    \"\"\"Transformasi data menggunakan pandas (Python)\"\"\"\n",
        "\n",
        "    # Baca ulang data untuk kejelasan tutorial\n",
        "    products_df = pd.read_csv('data/products.csv')\n",
        "    stores_df = pd.read_csv('data/stores.csv')\n",
        "    customers_df = pd.read_csv('data/customers_dirty.csv')\n",
        "    transactions_df = pd.read_csv('data/transactions.csv')\n",
        "\n",
        "    # 1. Transformasi dimensi produk\n",
        "    # Implementasi Slowly Changing Dimension (SCD) Type 2 sederhana\n",
        "    dim_product = products_df.copy()\n",
        "    dim_product['product_key'] = dim_product['product_id']  # Dalam kasus ini menggunakan ID yang sama\n",
        "    dim_product['effective_date'] = '2022-01-01'  # Tanggal efektif\n",
        "    dim_product['expiration_date'] = None  # Tidak berakhir karena ini adalah data awal\n",
        "    dim_product['current_flag'] = True  # Semua catatan aktif\n",
        "\n",
        "    dim_product = dim_product.rename(columns={\n",
        "        'name': 'product_name',\n",
        "        'base_cost': 'unit_cost',\n",
        "        'base_price': 'unit_price'\n",
        "    })\n",
        "\n",
        "    # 2. Transformasi dimensi toko\n",
        "    dim_store = stores_df.copy()\n",
        "    dim_store['store_key'] = dim_store['store_id']  # Dalam kasus ini menggunakan ID yang sama\n",
        "    dim_store['effective_date'] = '2022-01-01'  # Tanggal efektif\n",
        "    dim_store['expiration_date'] = None  # Tidak berakhir karena ini adalah data awal\n",
        "    dim_store['current_flag'] = True  # Semua catatan aktif\n",
        "\n",
        "    dim_store = dim_store.rename(columns={'name': 'store_name', 'type': 'store_type'})\n",
        "\n",
        "    # 3. Transformasi dimensi pelanggan (dengan pembersihan data)\n",
        "    # Pembersihan data pelanggan\n",
        "    dim_customer = customers_df.copy()\n",
        "\n",
        "    # Menangani nilai yang hilang\n",
        "    dim_customer['first_name'] = dim_customer['first_name'].fillna('Unknown')\n",
        "    dim_customer['last_name'] = dim_customer['last_name'].fillna('Unknown')\n",
        "    dim_customer['email'] = dim_customer['email'].fillna('unknown@example.com')\n",
        "\n",
        "    # Standarisasi kota (kapitalisasi yang konsisten)\n",
        "    dim_customer['city'] = dim_customer['city'].str.title()\n",
        "\n",
        "    # Menangani duplikat berdasarkan email (yang seharusnya unik)\n",
        "    dim_customer = dim_customer.drop_duplicates(subset=['email'], keep='first')\n",
        "\n",
        "    # Tambahkan kolom untuk SCD Type 2\n",
        "    dim_customer['customer_key'] = range(1, len(dim_customer) + 1)  # Buat surrogate key baru\n",
        "    dim_customer['effective_date'] = '2022-01-01'  # Tanggal efektif\n",
        "    dim_customer['expiration_date'] = None  # Tidak berakhir karena ini adalah data awal\n",
        "    dim_customer['current_flag'] = True  # Semua catatan aktif\n",
        "\n",
        "    # 4. Transformasi fakta penjualan\n",
        "    # Konversi string ke tanggal\n",
        "    transactions_df['date'] = pd.to_datetime(transactions_df['date'])\n",
        "\n",
        "    # Buat date_key berdasarkan format YYYYMMDD\n",
        "    transactions_df['date_key'] = transactions_df['date'].dt.strftime('%Y%m%d').astype(int)\n",
        "\n",
        "    # Gunakan pandas merge untuk menggabungkan dengan dimensi untuk mendapatkan kunci surrogate\n",
        "    # Simulasi fakta setelah dimensi dibangun\n",
        "    fact_sales = transactions_df.copy()\n",
        "\n",
        "    # Ganti sales_key dengan kunci surrogate\n",
        "    fact_sales['sales_key'] = range(1, len(fact_sales) + 1)\n",
        "\n",
        "    # Rename kolom untuk kejelasan\n",
        "    fact_sales = fact_sales.rename(columns={\n",
        "        'total_amount': 'sales_amount'\n",
        "    })\n",
        "\n",
        "    # Hapus kolom yang tidak diperlukan lagi\n",
        "    # fact_sales = fact_sales.drop(['date'], axis=1)\n",
        "\n",
        "    return dim_product, dim_store, dim_customer, fact_sales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIeGjf6-rCsV"
      },
      "source": [
        "Transformasi dengan pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OPPKBEorCsV"
      },
      "outputs": [],
      "source": [
        "dim_product_pd, dim_store_pd, dim_customer_pd, fact_sales_pd = transform_with_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BdRQTndrCsV"
      },
      "outputs": [],
      "source": [
        "print(\"Transformasi pandas selesai:\")\n",
        "print(f\"- Dimensi produk: {len(dim_product_pd)} baris\")\n",
        "print(f\"- Dimensi toko: {len(dim_store_pd)} baris\")\n",
        "print(f\"- Dimensi pelanggan: {len(dim_customer_pd)} baris\")\n",
        "print(f\"- Fakta penjualan: {len(fact_sales_pd)} baris\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJAAlnW4rCsV"
      },
      "outputs": [],
      "source": [
        "def transform_with_sql():\n",
        "    \"\"\"Transformasi data menggunakan SQL di DuckDB\"\"\"\n",
        "\n",
        "    # 1. Buat tabel staging untuk data sumber\n",
        "    conn.execute(\"CREATE OR REPLACE TABLE staging_products AS SELECT * FROM read_csv_auto('data/products.csv')\")\n",
        "    conn.execute(\"CREATE OR REPLACE TABLE staging_stores AS SELECT * FROM read_csv_auto('data/stores.csv')\")\n",
        "    conn.execute(\"CREATE OR REPLACE TABLE staging_customers AS SELECT * FROM read_csv_auto('data/customers_dirty.csv')\")\n",
        "    conn.execute(\"CREATE OR REPLACE TABLE staging_transactions AS SELECT * FROM read_csv_auto('data/transactions.csv')\")\n",
        "\n",
        "    # 2. Transformasi dimensi produk dengan SQL\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE staging_dim_product AS\n",
        "    SELECT\n",
        "        product_id AS product_key,\n",
        "        product_id,\n",
        "        name AS product_name,\n",
        "        category,\n",
        "        subcategory,\n",
        "        base_cost AS unit_cost,\n",
        "        base_price AS unit_price,\n",
        "        '2022-01-01'::DATE AS effective_date,\n",
        "        NULL::DATE AS expiration_date,\n",
        "        TRUE AS current_flag\n",
        "    FROM staging_products\n",
        "    \"\"\")\n",
        "\n",
        "    # 3. Transformasi dimensi toko dengan SQL\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE staging_dim_store AS\n",
        "    SELECT\n",
        "        store_id AS store_key,\n",
        "        store_id,\n",
        "        name AS store_name,\n",
        "        city,\n",
        "        region,\n",
        "        type AS store_type,\n",
        "        '2022-01-01'::DATE AS effective_date,\n",
        "        NULL::DATE AS expiration_date,\n",
        "        TRUE AS current_flag\n",
        "    FROM staging_stores\n",
        "    \"\"\")\n",
        "\n",
        "    # 4. Transformasi dimensi pelanggan dengan SQL (termasuk data cleansing)\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE staging_dim_customer AS\n",
        "    WITH clean_customers AS (\n",
        "        SELECT\n",
        "            customer_id,\n",
        "            COALESCE(first_name, 'Unknown') AS first_name,\n",
        "            COALESCE(last_name, 'Unknown') AS last_name,\n",
        "            COALESCE(email, 'unknown@example.com') AS email,\n",
        "            CASE\n",
        "                WHEN city IS NULL THEN 'Unknown'\n",
        "                ELSE UPPER(SUBSTRING(LOWER(city), 1, 1)) || SUBSTRING(LOWER(city), 2) -- Standarisasi kapitalisasi\n",
        "            END AS city,\n",
        "            membership,\n",
        "            -- Ambil hanya baris pertama untuk email duplikat\n",
        "            ROW_NUMBER() OVER (PARTITION BY email ORDER BY customer_id) AS rn\n",
        "        FROM staging_customers\n",
        "    )\n",
        "    SELECT\n",
        "        ROW_NUMBER() OVER (ORDER BY customer_id) AS customer_key,\n",
        "        customer_id,\n",
        "        first_name,\n",
        "        last_name,\n",
        "        email,\n",
        "        city,\n",
        "        membership,\n",
        "        '2022-01-01'::DATE AS effective_date,\n",
        "        NULL::DATE AS expiration_date,\n",
        "        TRUE AS current_flag\n",
        "    FROM clean_customers\n",
        "    WHERE rn = 1 -- Eliminasi duplikat\n",
        "    \"\"\")\n",
        "\n",
        "    # 5. Transformasi fakta penjualan dengan SQL\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE staging_fact_sales AS\n",
        "    SELECT\n",
        "        ROW_NUMBER() OVER (ORDER BY transaction_id, product_id) AS sales_key,\n",
        "        transaction_id,\n",
        "        STRFTIME(date, '%Y%m%d')::INTEGER AS date_key,\n",
        "        product_id AS product_key, -- Akan diganti nanti dengan JOIN\n",
        "        store_id AS store_key, -- Akan diganti nanti dengan JOIN\n",
        "        customer_id AS customer_key, -- Akan diganti nanti dengan JOIN\n",
        "        quantity,\n",
        "        unit_price,\n",
        "        unit_cost,\n",
        "        discount_pct,\n",
        "        discount_amount,\n",
        "        total_amount AS sales_amount,\n",
        "        profit AS profit_amount\n",
        "    FROM staging_transactions\n",
        "    \"\"\")\n",
        "\n",
        "    # Dapatkan jumlah baris\n",
        "    product_count = conn.execute(\"SELECT COUNT(*) FROM staging_dim_product\").fetchone()[0]\n",
        "    store_count = conn.execute(\"SELECT COUNT(*) FROM staging_dim_store\").fetchone()[0]\n",
        "    customer_count = conn.execute(\"SELECT COUNT(*) FROM staging_dim_customer\").fetchone()[0]\n",
        "    sales_count = conn.execute(\"SELECT COUNT(*) FROM staging_fact_sales\").fetchone()[0]\n",
        "\n",
        "    print(\"Transformasi SQL selesai:\")\n",
        "    print(f\"- Dimensi produk: {product_count} baris\")\n",
        "    print(f\"- Dimensi toko: {store_count} baris\")\n",
        "    print(f\"- Dimensi pelanggan: {customer_count} baris\")\n",
        "    print(f\"- Fakta penjualan: {sales_count} baris\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8VHU220rCsW"
      },
      "source": [
        "Transformasi dengan SQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4K1tliHrCsW"
      },
      "outputs": [],
      "source": [
        "transform_with_sql()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufo-uVEerCsW"
      },
      "source": [
        "### 5.3 Load - Memuat Data ke Data Warehouse<br>\n",
        "<br>\n",
        "Kita akan mengimplementasikan dua opsi loading:<br>\n",
        "1. Load dari pandas DataFrame<br>\n",
        "2. Load dari tabel staging SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QIxYOq8rCsW"
      },
      "source": [
        "In[12]:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R02FPcS5rCsW"
      },
      "outputs": [],
      "source": [
        "def load_from_pandas(dim_product, dim_store, dim_customer, fact_sales):\n",
        "    \"\"\"Memuat data dari pandas DataFrame ke data warehouse\"\"\"\n",
        "\n",
        "    # 1. Muat dimensi produk\n",
        "    conn.execute(\"DELETE FROM dim_product\")  # Bersihkan tabel sasaran\n",
        "    conn.execute(\"INSERT INTO dim_product SELECT * FROM dim_product\")\n",
        "\n",
        "    # 2. Muat dimensi toko\n",
        "    conn.execute(\"DELETE FROM dim_store\")  # Bersihkan tabel sasaran\n",
        "    conn.execute(\"INSERT INTO dim_store SELECT * FROM dim_store\")\n",
        "\n",
        "    # 3. Muat dimensi pelanggan\n",
        "    conn.execute(\"DELETE FROM dim_customer\")  # Bersihkan tabel sasaran\n",
        "    conn.execute(\"INSERT INTO dim_customer SELECT * FROM dim_customer\")\n",
        "\n",
        "    # 4. Muat fakta penjualan\n",
        "    # Sebelum memuat, kita perlu menyelaraskan kunci surrogate dengan dimensi\n",
        "\n",
        "    # Buat tabel sementara untuk fakta\n",
        "    conn.execute(\"CREATE OR REPLACE TABLE temp_fact_sales AS SELECT * FROM fact_sales\")\n",
        "\n",
        "    # 5. Muat fakta penjualan setelah pemetaan kunci\n",
        "    conn.execute(\"\"\"\n",
        "    INSERT INTO fact_sales\n",
        "    SELECT\n",
        "        f.sales_key,\n",
        "        f.transaction_id,\n",
        "        f.date_key,\n",
        "        p.product_key,\n",
        "        s.store_key,\n",
        "        c.customer_key,\n",
        "        f.quantity,\n",
        "        f.unit_price,\n",
        "        f.unit_cost,\n",
        "        f.discount_pct,\n",
        "        f.discount_amount,\n",
        "        f.sales_amount,\n",
        "        f.profit_amount\n",
        "    FROM temp_fact_sales f\n",
        "    JOIN dim_product p ON f.product_key = p.product_id\n",
        "    JOIN dim_store s ON f.store_key = s.store_id\n",
        "    JOIN dim_customer c ON f.customer_key = c.customer_id\n",
        "    \"\"\")\n",
        "\n",
        "    # Hapus tabel sementara\n",
        "    conn.execute(\"DROP TABLE temp_fact_sales\")\n",
        "\n",
        "    # Menghitung jumlah baris yang dimuat\n",
        "    product_count = conn.execute(\"SELECT COUNT(*) FROM dim_product\").fetchone()[0]\n",
        "    store_count = conn.execute(\"SELECT COUNT(*) FROM dim_store\").fetchone()[0]\n",
        "    customer_count = conn.execute(\"SELECT COUNT(*) FROM dim_customer\").fetchone()[0]\n",
        "    sales_count = conn.execute(\"SELECT COUNT(*) FROM fact_sales\").fetchone()[0]\n",
        "\n",
        "    print(\"Data dari pandas berhasil dimuat ke data warehouse:\")\n",
        "    print(f\"- Dimensi produk: {product_count} baris\")\n",
        "    print(f\"- Dimensi toko: {store_count} baris\")\n",
        "    print(f\"- Dimensi pelanggan: {customer_count} baris\")\n",
        "    print(f\"- Fakta penjualan: {sales_count} baris\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvXr4N33rCsX"
      },
      "outputs": [],
      "source": [
        "def load_from_staging():\n",
        "    \"\"\"Memuat data dari tabel staging SQL ke data warehouse\"\"\"\n",
        "\n",
        "    # 1. Muat dimensi produk\n",
        "    conn.execute(\"DELETE FROM dim_product\")  # Bersihkan tabel sasaran\n",
        "    conn.execute(\"INSERT INTO dim_product SELECT * FROM staging_dim_product\")\n",
        "\n",
        "    # 2. Muat dimensi toko\n",
        "    conn.execute(\"DELETE FROM dim_store\")  # Bersihkan tabel sasaran\n",
        "    conn.execute(\"INSERT INTO dim_store SELECT * FROM staging_dim_store\")\n",
        "\n",
        "    # 3. Muat dimensi pelanggan\n",
        "    conn.execute(\"DELETE FROM dim_customer\")  # Bersihkan tabel sasaran\n",
        "    conn.execute(\"INSERT INTO dim_customer SELECT * FROM staging_dim_customer\")\n",
        "\n",
        "    # 4. Muat fakta penjualan dengan pemetaan kunci yang benar\n",
        "    conn.execute(\"DELETE FROM fact_sales\")  # Bersihkan tabel sasaran\n",
        "    conn.execute(\"\"\"\n",
        "    INSERT INTO fact_sales\n",
        "    SELECT\n",
        "        f.sales_key,\n",
        "        f.transaction_id,\n",
        "        f.date_key,\n",
        "        p.product_key,\n",
        "        s.store_key,\n",
        "        c.customer_key,\n",
        "        f.quantity,\n",
        "        f.unit_price,\n",
        "        f.unit_cost,\n",
        "        f.discount_pct,\n",
        "        f.discount_amount,\n",
        "        f.sales_amount,\n",
        "        f.profit_amount\n",
        "    FROM staging_fact_sales f\n",
        "    JOIN dim_product p ON f.product_key = p.product_id\n",
        "    JOIN dim_store s ON f.store_key = s.store_id\n",
        "    JOIN dim_customer c ON f.customer_key = c.customer_id\n",
        "    \"\"\")\n",
        "\n",
        "    # Menghitung jumlah baris yang dimuat\n",
        "    product_count = conn.execute(\"SELECT COUNT(*) FROM dim_product\").fetchone()[0]\n",
        "    store_count = conn.execute(\"SELECT COUNT(*) FROM dim_store\").fetchone()[0]\n",
        "    customer_count = conn.execute(\"SELECT COUNT(*) FROM dim_customer\").fetchone()[0]\n",
        "    sales_count = conn.execute(\"SELECT COUNT(*) FROM fact_sales\").fetchone()[0]\n",
        "\n",
        "    print(\"Data dari staging berhasil dimuat ke data warehouse:\")\n",
        "    print(f\"- Dimensi produk: {product_count} baris\")\n",
        "    print(f\"- Dimensi toko: {store_count} baris\")\n",
        "    print(f\"- Dimensi pelanggan: {customer_count} baris\")\n",
        "    print(f\"- Fakta penjualan: {sales_count} baris\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzvT8Ge0rCsX"
      },
      "source": [
        "Pilih salah satu metode loading:<br>\n",
        "load_from_pandas(dim_product_pd, dim_store_pd, dim_customer_pd, fact_sales_pd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-RNLnllrCsX"
      },
      "outputs": [],
      "source": [
        "load_from_staging()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8UnBKVLrCsX"
      },
      "source": [
        "## 6. Implementasi Snowflake Schema<br>\n",
        "<br>\n",
        "Mari buat versi Snowflake Schema dari model kita dengan menormalisasi dimensi produk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBlENM6erCsX"
      },
      "outputs": [],
      "source": [
        "def create_snowflake_schema():\n",
        "    \"\"\"Mengimplementasikan Snowflake Schema dari dimensi produk\"\"\"\n",
        "\n",
        "    # Drop existing tables in the correct order to handle dependencies\n",
        "    conn.execute(\"DROP TABLE IF EXISTS dim_product_snowflake\")\n",
        "    conn.execute(\"DROP TABLE IF EXISTS dim_subcategory\")\n",
        "    conn.execute(\"DROP TABLE IF EXISTS dim_category\")\n",
        "\n",
        "    # 1. Buat tabel kategori\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE TABLE dim_category AS\n",
        "    SELECT\n",
        "        ROW_NUMBER() OVER (ORDER BY category) AS category_key,\n",
        "        category AS category_name\n",
        "    FROM (SELECT DISTINCT category FROM dim_product)\n",
        "    \"\"\")\n",
        "\n",
        "    # 2. Buat tabel subkategori\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE TABLE dim_subcategory AS\n",
        "    WITH subcategory_data AS (\n",
        "        SELECT DISTINCT\n",
        "            subcategory,\n",
        "            category\n",
        "        FROM dim_product\n",
        "    )\n",
        "    SELECT\n",
        "        ROW_NUMBER() OVER (ORDER BY s.subcategory) AS subcategory_key,\n",
        "        s.subcategory AS subcategory_name,\n",
        "        c.category_key\n",
        "    FROM subcategory_data s\n",
        "    JOIN dim_category c ON s.category = c.category_name\n",
        "    \"\"\")\n",
        "\n",
        "    # 3. Buat versi snowflake dari tabel produk\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE TABLE dim_product_snowflake AS\n",
        "    SELECT\n",
        "        p.product_key,\n",
        "        p.product_id,\n",
        "        p.product_name,\n",
        "        c.category_key,\n",
        "        s.subcategory_key,\n",
        "        p.unit_cost,\n",
        "        p.unit_price,\n",
        "        p.effective_date,\n",
        "        p.expiration_date,\n",
        "        p.current_flag\n",
        "    FROM dim_product p\n",
        "    JOIN dim_category c ON p.category = c.category_name\n",
        "    JOIN dim_subcategory s ON p.subcategory = s.subcategory_name AND s.category_key = c.category_key\n",
        "    \"\"\")\n",
        "\n",
        "    # Menghitung jumlah baris\n",
        "    category_count = conn.execute(\"SELECT COUNT(*) FROM dim_category\").fetchone()[0]\n",
        "    subcategory_count = conn.execute(\"SELECT COUNT(*) FROM dim_subcategory\").fetchone()[0]\n",
        "    product_count = conn.execute(\"SELECT COUNT(*) FROM dim_product_snowflake\").fetchone()[0]\n",
        "\n",
        "    print(\"Snowflake schema berhasil dibuat:\")\n",
        "    print(f\"- Dimensi kategori: {category_count} baris\")\n",
        "    print(f\"- Dimensi subkategori: {subcategory_count} baris\")\n",
        "    print(f\"- Dimensi produk (snowflake): {product_count} baris\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX4ZDYwLrCsb"
      },
      "source": [
        "Buat snowflake schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESaq5NcvrCsb"
      },
      "outputs": [],
      "source": [
        "create_snowflake_schema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvcBA1WPrCsb"
      },
      "source": [
        "## 7. Implementasi Fact Constellation (Galaxy Schema)<br>\n",
        "<br>\n",
        "Sekarang kita akan menambahkan tabel fakta kedua untuk inventaris produk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gjS6PdYrCsc"
      },
      "outputs": [],
      "source": [
        "def create_fact_constellation():\n",
        "    \"\"\"Mengimplementasikan Fact Constellation dengan menambahkan tabel fakta inventaris\"\"\"\n",
        "\n",
        "    # 1. Buat tabel fakta inventaris\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE fact_inventory (\n",
        "        inventory_key INTEGER PRIMARY KEY,\n",
        "        date_key INTEGER,\n",
        "        product_key INTEGER,\n",
        "        store_key INTEGER,\n",
        "        quantity_on_hand INTEGER,\n",
        "        quantity_received INTEGER,\n",
        "        quantity_sold INTEGER,\n",
        "        stock_value DECIMAL(10,2),\n",
        "\n",
        "        FOREIGN KEY (date_key) REFERENCES dim_date(date_key),\n",
        "        FOREIGN KEY (product_key) REFERENCES dim_product(product_key),\n",
        "        FOREIGN KEY (store_key) REFERENCES dim_store(store_key)\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    # 2. Buat data inventaris berdasarkan data penjualan (simulasi)\n",
        "    conn.execute(\"\"\"\n",
        "    -- Data inventaris untuk bulan terakhir\n",
        "    WITH latest_month AS (\n",
        "        SELECT\n",
        "            MAX(date) as max_date,\n",
        "            EXTRACT(YEAR FROM MAX(date)) as year,\n",
        "            EXTRACT(MONTH FROM MAX(date)) as month\n",
        "        FROM dim_date\n",
        "    ),\n",
        "\n",
        "    month_dates AS (\n",
        "        SELECT\n",
        "            date_key,\n",
        "            date\n",
        "        FROM\n",
        "            dim_date,\n",
        "            latest_month\n",
        "        WHERE\n",
        "            EXTRACT(YEAR FROM date) = latest_month.year AND\n",
        "            EXTRACT(MONTH FROM date) = latest_month.month\n",
        "        ORDER BY\n",
        "            date\n",
        "    ),\n",
        "\n",
        "    store_products AS (\n",
        "        SELECT DISTINCT\n",
        "            s.store_key,\n",
        "            p.product_key\n",
        "        FROM\n",
        "            dim_store s,\n",
        "            dim_product p\n",
        "        ORDER BY\n",
        "            s.store_key, p.product_key\n",
        "        LIMIT 300 -- Batasi kombinasi untuk sampel\n",
        "    )\n",
        "\n",
        "    INSERT INTO fact_inventory\n",
        "    WITH inventory_data AS (\n",
        "        SELECT\n",
        "            md.date_key,\n",
        "            sp.store_key,\n",
        "            sp.product_key,\n",
        "            -- Acak untuk data contoh\n",
        "            CAST(RANDOM() * 100 AS INTEGER) AS base_qty_on_hand,\n",
        "            CAST(RANDOM() * 20 AS INTEGER) AS base_qty_received,\n",
        "            CAST(RANDOM() * 15 AS INTEGER) AS base_qty_sold\n",
        "        FROM\n",
        "            month_dates md\n",
        "        CROSS JOIN\n",
        "            store_products sp\n",
        "    ),\n",
        "\n",
        "    -- Tambahkan running total untuk membuat data inventaris yang masuk akal\n",
        "    running_inventory AS (\n",
        "        SELECT\n",
        "            id.date_key,\n",
        "            id.store_key,\n",
        "            id.product_key,\n",
        "            id.base_qty_received AS quantity_received,\n",
        "            id.base_qty_sold AS quantity_sold,\n",
        "            CASE\n",
        "                WHEN ROW_NUMBER() OVER (PARTITION BY id.store_key, id.product_key ORDER BY id.date_key) = 1\n",
        "                THEN id.base_qty_on_hand\n",
        "                ELSE NULL -- Akan diisi nanti\n",
        "            END AS initial_qty\n",
        "        FROM\n",
        "            inventory_data id\n",
        "    ),\n",
        "\n",
        "    final_inventory AS (\n",
        "        SELECT\n",
        "            date_key,\n",
        "            store_key,\n",
        "            product_key,\n",
        "            quantity_received,\n",
        "            quantity_sold,\n",
        "            SUM(COALESCE(initial_qty, 0)) OVER (\n",
        "                PARTITION BY store_key, product_key\n",
        "                ORDER BY date_key\n",
        "                ROWS UNBOUNDED PRECEDING\n",
        "            )\n",
        "            + SUM(quantity_received) OVER (\n",
        "                PARTITION BY store_key, product_key\n",
        "                ORDER BY date_key\n",
        "                ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
        "            )\n",
        "            - SUM(quantity_sold) OVER (\n",
        "                PARTITION BY store_key, product_key\n",
        "                ORDER BY date_key\n",
        "                ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
        "            )\n",
        "            + COALESCE(initial_qty, 0)\n",
        "            AS quantity_on_hand\n",
        "        FROM\n",
        "            running_inventory\n",
        "    )\n",
        "\n",
        "    SELECT\n",
        "        ROW_NUMBER() OVER (ORDER BY fi.date_key, fi.store_key, fi.product_key) AS inventory_key,\n",
        "        fi.date_key,\n",
        "        fi.product_key,  -- Specify table alias\n",
        "        fi.store_key,\n",
        "        fi.quantity_on_hand,\n",
        "        fi.quantity_received,\n",
        "        fi.quantity_sold,\n",
        "        fi.quantity_on_hand * dp.unit_cost AS stock_value\n",
        "    FROM\n",
        "        final_inventory fi\n",
        "    JOIN\n",
        "        dim_product dp ON fi.product_key = dp.product_key\n",
        "    \"\"\")\n",
        "\n",
        "    # Menghitung jumlah baris\n",
        "    inventory_count = conn.execute(\"SELECT COUNT(*) FROM fact_inventory\").fetchone()[0]\n",
        "\n",
        "    print(f\"Fact Constellation berhasil dibuat dengan tabel fakta inventaris ({inventory_count} baris)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCKN8dC6rCsc"
      },
      "source": [
        "Buat fact constellation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJdssFYCrCsc"
      },
      "outputs": [],
      "source": [
        "create_fact_constellation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gANdHXwsrCsc"
      },
      "source": [
        "## 8. Implementasi SCD (Slowly Changing Dimension) Type 2<br>\n",
        "<br>\n",
        "Tunjukkan bagaimana menangani perubahan data yang perlu dilacak secara historis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKNRvv5irCsc"
      },
      "outputs": [],
      "source": [
        "def implement_scd_type2():\n",
        "    \"\"\"Implementasi SCD Type 2 untuk dimensi pelanggan\"\"\"\n",
        "\n",
        "    # 1. Simulasi perubahan data (dengan pandas)\n",
        "    # Ambil beberapa pelanggan dan ubah data mereka\n",
        "    customers_df = pd.read_csv('data/customers.csv')\n",
        "\n",
        "    # Pilih 10 pelanggan secara acak untuk diubah datanya\n",
        "    updated_customers = customers_df.sample(10).copy()\n",
        "\n",
        "    # Ubah beberapa data\n",
        "    for idx, row in updated_customers.iterrows():\n",
        "        if np.random.random() < 0.5:\n",
        "            # Perubahan kota\n",
        "            updated_customers.loc[idx, 'city'] = np.random.choice(['Jakarta Selatan', 'Bandung Barat',\n",
        "                                                              'Surabaya Timur', 'Medan Utara'])\n",
        "        else:\n",
        "            # Perubahan membership\n",
        "            current_membership = updated_customers.loc[idx, 'membership']\n",
        "            new_membership = np.random.choice(['Silver', 'Gold', 'Platinum', 'Regular'])\n",
        "            # Pastikan membership baru berbeda\n",
        "            while new_membership == current_membership:\n",
        "                new_membership = np.random.choice(['Silver', 'Gold', 'Platinum', 'Regular'])\n",
        "            updated_customers.loc[idx, 'membership'] = new_membership\n",
        "\n",
        "    # Simpan pelanggan yang diperbarui untuk diekstrak\n",
        "    updated_customers.to_csv('data/updated_customers.csv', index=False)\n",
        "\n",
        "    # 2. Ekstrak dan bersihkan data yang diperbarui\n",
        "    conn.execute(\"CREATE OR REPLACE TABLE staging_updated_customers AS SELECT * FROM read_csv_auto('data/updated_customers.csv')\")\n",
        "\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE staging_updated_customers_clean AS\n",
        "    SELECT\n",
        "        customer_id,\n",
        "        COALESCE(first_name, 'Unknown') AS first_name,\n",
        "        COALESCE(last_name, 'Unknown') AS last_name,\n",
        "        COALESCE(email, 'unknown@example.com') AS email,\n",
        "        CASE\n",
        "            WHEN city IS NULL THEN 'Unknown'\n",
        "            ELSE LOWER(city) -- Standarisasi menjadi lowercase karena INITCAP tidak ada di DuckDB\n",
        "        END AS city,\n",
        "        membership,\n",
        "        CURRENT_DATE AS effective_date\n",
        "    FROM staging_updated_customers\n",
        "    \"\"\")\n",
        "\n",
        "    # 3. Identifikasi perubahan\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE customer_changes AS\n",
        "    SELECT\n",
        "        s.customer_id,\n",
        "        s.first_name,\n",
        "        s.last_name,\n",
        "        s.email,\n",
        "        s.city,\n",
        "        s.membership,\n",
        "        s.effective_date,\n",
        "        CASE\n",
        "            WHEN d.customer_id IS NULL THEN 'NEW'\n",
        "            WHEN (s.city != d.city OR s.membership != d.membership) THEN 'CHANGED'\n",
        "            ELSE 'UNCHANGED'\n",
        "        END AS change_type\n",
        "    FROM\n",
        "        staging_updated_customers_clean s\n",
        "    LEFT JOIN\n",
        "        dim_customer d\n",
        "    ON\n",
        "        s.customer_id = d.customer_id\n",
        "        AND d.current_flag = TRUE\n",
        "    \"\"\")\n",
        "\n",
        "    # 4. Implementasi SCD Type 2 - Mengakhiri catatan lama\n",
        "    conn.execute(\"\"\"\n",
        "    UPDATE dim_customer\n",
        "    SET\n",
        "        current_flag = FALSE,\n",
        "        expiration_date = CURRENT_DATE - INTERVAL '1 day'\n",
        "    WHERE\n",
        "        customer_id IN (SELECT customer_id FROM customer_changes WHERE change_type = 'CHANGED')\n",
        "        AND current_flag = TRUE\n",
        "    \"\"\")\n",
        "\n",
        "    # 5. Implementasi SCD Type 2 - Menambahkan catatan baru\n",
        "    conn.execute(\"\"\"\n",
        "    INSERT INTO dim_customer\n",
        "    SELECT\n",
        "        (SELECT MAX(customer_key) FROM dim_customer) + ROW_NUMBER() OVER (ORDER BY customer_id) AS customer_key,\n",
        "        customer_id,\n",
        "        first_name,\n",
        "        last_name,\n",
        "        email,\n",
        "        city,\n",
        "        membership,\n",
        "        effective_date,\n",
        "        NULL AS expiration_date,\n",
        "        TRUE AS current_flag\n",
        "    FROM\n",
        "        customer_changes\n",
        "    WHERE\n",
        "        change_type = 'CHANGED'\n",
        "    \"\"\")\n",
        "\n",
        "    # Menampilkan perubahan\n",
        "    changes_count = conn.execute(\"SELECT change_type, COUNT(*) FROM customer_changes GROUP BY change_type\").fetchdf()\n",
        "    print(\"Perubahan dimensi pelanggan:\")\n",
        "    print(changes_count)\n",
        "\n",
        "    # Tampilkan contoh historis\n",
        "    if conn.execute(\"SELECT COUNT(*) FROM customer_changes WHERE change_type = 'CHANGED'\").fetchone()[0] > 0:\n",
        "        changed_id = conn.execute(\"SELECT customer_id FROM customer_changes WHERE change_type = 'CHANGED' LIMIT 1\").fetchone()[0]\n",
        "\n",
        "        history = conn.execute(f\"\"\"\n",
        "            SELECT\n",
        "                customer_key,\n",
        "                customer_id,\n",
        "                city,\n",
        "                membership,\n",
        "                effective_date,\n",
        "                expiration_date,\n",
        "                current_flag\n",
        "            FROM\n",
        "                dim_customer\n",
        "            WHERE\n",
        "                customer_id = {changed_id}\n",
        "            ORDER BY\n",
        "                effective_date\n",
        "        \"\"\").fetchdf()\n",
        "\n",
        "        print(f\"\\nContoh riwayat untuk pelanggan {changed_id}:\")\n",
        "        print(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mprVJO09rCsc"
      },
      "source": [
        "Implementasi SCD Type 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9YEjYeWrCsd"
      },
      "outputs": [],
      "source": [
        "implement_scd_type2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm8Nj7RJrCsd"
      },
      "source": [
        "## 9. Implementasi Incremental ETL<br>\n",
        "<br>\n",
        "Kita akan menunjukkan bagaimana melakukan ETL inkremental, di mana hanya data baru yang diproses:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC-Vhs_ZrCsd"
      },
      "outputs": [],
      "source": [
        "def generate_incremental_data():\n",
        "    \"\"\"Menghasilkan data baru untuk diproses inkremental\"\"\"\n",
        "\n",
        "    # 1. Baca data transaksi yang ada\n",
        "    transactions_df = pd.read_csv('data/transactions.csv')\n",
        "\n",
        "    # 2. Buat transaksi baru dengan tanggal yang lebih baru\n",
        "    new_transactions = []\n",
        "\n",
        "    start_date = datetime(2024, 1, 1)\n",
        "    end_date = datetime(2024, 1, 10)\n",
        "\n",
        "    for i in range(500):  # Buat 500 transaksi baru\n",
        "        tx_date = start_date + timedelta(days=np.random.randint(0, (end_date-start_date).days))\n",
        "\n",
        "        # Pilih store, customer, dan product secara acak dari data yang ada\n",
        "        store_id = np.random.choice(transactions_df['store_id'].unique())\n",
        "        customer_id = np.random.choice(transactions_df['customer_id'].unique())\n",
        "        product_id = np.random.choice(transactions_df['product_id'].unique())\n",
        "\n",
        "        # Dapatkan data produk\n",
        "        product_info = transactions_df[transactions_df['product_id'] == product_id].iloc[0]\n",
        "\n",
        "        # Simulasi variasi harga\n",
        "        price_variance = np.random.uniform(0.9, 1.1)\n",
        "        price = round(product_info['unit_price'] * price_variance, 2)\n",
        "\n",
        "        cost_variance = np.random.uniform(0.95, 1.05)\n",
        "        cost = round(product_info['unit_cost'] * cost_variance, 2)\n",
        "\n",
        "        quantity = np.random.randint(1, 6)\n",
        "\n",
        "        # Diskon kadang diberikan\n",
        "        discount_pct = 0\n",
        "        if np.random.random() < 0.3:  # 30% transaksi mendapat diskon\n",
        "            discount_pct = np.random.choice([5, 10, 15, 20, 25, 50]) / 100\n",
        "\n",
        "        discount_amount = round(price * quantity * discount_pct, 2)\n",
        "        total = round(price * quantity - discount_amount, 2)\n",
        "        profit = round(total - (cost * quantity), 2)\n",
        "\n",
        "        new_transactions.append({\n",
        "            'transaction_id': f'TX-NEW-{i+1}',\n",
        "            'date': tx_date.strftime('%Y-%m-%d'),\n",
        "            'store_id': store_id,\n",
        "            'customer_id': customer_id,\n",
        "            'product_id': product_id,\n",
        "            'quantity': quantity,\n",
        "            'unit_price': price,\n",
        "            'unit_cost': cost,\n",
        "            'discount_pct': discount_pct,\n",
        "            'discount_amount': discount_amount,\n",
        "            'total_amount': total,\n",
        "            'profit': profit\n",
        "        })\n",
        "\n",
        "    # Simpan data baru\n",
        "    new_tx_df = pd.DataFrame(new_transactions)\n",
        "    new_tx_df.to_csv('data/new_transactions.csv', index=False)\n",
        "\n",
        "    print(f\"Generated {len(new_transactions)} new transactions for incremental processing\")\n",
        "    return new_tx_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUQ_LaPLrCsd"
      },
      "outputs": [],
      "source": [
        "def incremental_etl():\n",
        "    \"\"\"Proses ETL inkremental hanya untuk data baru\"\"\"\n",
        "\n",
        "    # 1. Ekstrak data baru\n",
        "    # Generate data baru dahulu\n",
        "    generate_incremental_data()\n",
        "\n",
        "    # Dapatkan tanggal terakhir yang sudah diproses\n",
        "    last_date = conn.execute(\"\"\"\n",
        "        SELECT MAX(d.date)\n",
        "        FROM fact_sales f\n",
        "        JOIN dim_date d ON f.date_key = d.date_key\n",
        "    \"\"\").fetchone()[0]\n",
        "\n",
        "    print(f\"Tanggal terakhir terproses: {last_date}\")\n",
        "\n",
        "    # Ekstrak data baru dan filter transaksi yang sudah ada\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE staging_new_transactions AS\n",
        "    SELECT * FROM read_csv_auto('data/new_transactions.csv') t\n",
        "    WHERE date::DATE > ?\n",
        "    AND NOT EXISTS (\n",
        "        SELECT 1 FROM fact_sales fs\n",
        "        WHERE fs.transaction_id = t.transaction_id\n",
        "    )\n",
        "    \"\"\", [last_date])\n",
        "\n",
        "    # Hitung jumlah transaksi baru\n",
        "    new_count = conn.execute(\"SELECT COUNT(*) FROM staging_new_transactions\").fetchone()[0]\n",
        "    print(f\"Ditemukan {new_count} transaksi baru yang unik untuk diproses\")\n",
        "\n",
        "    # Exit early if no new transactions to process\n",
        "    if new_count == 0:\n",
        "        print(\"Tidak ada transaksi baru untuk diproses\")\n",
        "        return\n",
        "\n",
        "    # 1.5 Identifikasi dan tambahkan tanggal baru ke dimensi tanggal\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE staging_new_dates AS\n",
        "    SELECT DISTINCT\n",
        "        strftime(date::DATE, '%Y%m%d')::INTEGER AS date_key,\n",
        "        date::DATE AS date,\n",
        "        EXTRACT(YEAR FROM date::DATE) AS year,\n",
        "        EXTRACT(MONTH FROM date::DATE) AS month,\n",
        "        EXTRACT(DAY FROM date::DATE) AS day,\n",
        "        EXTRACT(DOW FROM date::DATE) AS day_of_week\n",
        "    FROM staging_new_transactions\n",
        "    WHERE strftime(date::DATE, '%Y%m%d')::INTEGER NOT IN (SELECT date_key FROM dim_date)\n",
        "    \"\"\")\n",
        "\n",
        "    # Hitung jumlah tanggal baru\n",
        "    new_dates_count = conn.execute(\"SELECT COUNT(*) FROM staging_new_dates\").fetchone()[0]\n",
        "    print(f\"Menambahkan {new_dates_count} tanggal baru ke dalam dimensi tanggal\")\n",
        "\n",
        "    # Tambahkan tanggal baru ke dimensi tanggal jika ada\n",
        "    if new_dates_count > 0:\n",
        "        conn.execute(\"\"\"\n",
        "        INSERT INTO dim_date (date_key, date, year, month, day, day_of_week)\n",
        "        SELECT date_key, date, year, month, day, day_of_week\n",
        "        FROM staging_new_dates\n",
        "        \"\"\")\n",
        "\n",
        "    # 2. Dapatkan sales_key terakhir dari fact_sales untuk incremental key generation\n",
        "    max_sales_key = conn.execute(\"SELECT COALESCE(MAX(sales_key), 0) FROM fact_sales\").fetchone()[0]\n",
        "    print(f\"Sales key terakhir: {max_sales_key}\")\n",
        "\n",
        "    # Dapatkan daftar dari semua sales_key yang sudah ada untuk pengecekan\n",
        "    existing_keys = set()\n",
        "    for row in conn.execute(\"SELECT sales_key FROM fact_sales\").fetchall():\n",
        "        existing_keys.add(row[0])\n",
        "\n",
        "    # Dapatkan daftar dari semua transaction_id yang sudah ada untuk pengecekan\n",
        "    existing_transactions = set()\n",
        "    for row in conn.execute(\"SELECT transaction_id FROM fact_sales\").fetchall():\n",
        "        existing_transactions.add(row[0])\n",
        "\n",
        "    # 2. Buat staging untuk fact sales dengan perhitungan kunci yang benar-benar aman\n",
        "    conn.execute(\"\"\"\n",
        "    CREATE OR REPLACE TABLE staging_fact_sales_incremental AS\n",
        "    SELECT\n",
        "        0 AS sales_key, -- Placeholder, akan diupdate nanti\n",
        "        t.transaction_id,\n",
        "        strftime(t.date::DATE, '%Y%m%d')::INTEGER AS date_key,\n",
        "        t.product_id AS product_key,\n",
        "        t.store_id AS store_key,\n",
        "        t.customer_id AS customer_key,\n",
        "        t.quantity,\n",
        "        t.unit_price,\n",
        "        t.unit_cost,\n",
        "        t.discount_pct,\n",
        "        t.discount_amount,\n",
        "        t.total_amount AS sales_amount,\n",
        "        t.profit AS profit_amount\n",
        "    FROM staging_new_transactions t\n",
        "    WHERE t.transaction_id NOT IN (\n",
        "        SELECT transaction_id FROM fact_sales\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    # Update kunci sales dengan pengecekan keunikan\n",
        "    new_rows = conn.execute(\"SELECT transaction_id FROM staging_fact_sales_incremental\").fetchall()\n",
        "    start_key = max_sales_key + 1\n",
        "\n",
        "    for i, row in enumerate(new_rows):\n",
        "        transaction_id = row[0]\n",
        "        new_key = start_key + i\n",
        "\n",
        "        # Pastikan kunci baru tidak ada dalam daftar existing_keys\n",
        "        while new_key in existing_keys:\n",
        "            new_key += 1\n",
        "\n",
        "        # Update record dengan kunci yang aman\n",
        "        conn.execute(\"\"\"\n",
        "        UPDATE staging_fact_sales_incremental\n",
        "        SET sales_key = ?\n",
        "        WHERE transaction_id = ?\n",
        "        \"\"\", [new_key, transaction_id])\n",
        "\n",
        "        # Tambahkan ke set existing_keys untuk pengecekan berikutnya\n",
        "        existing_keys.add(new_key)\n",
        "\n",
        "    # Final check - pastikan tidak ada kunci duplikat dalam staging\n",
        "    dup_count = conn.execute(\"\"\"\n",
        "    SELECT COUNT(*) FROM (\n",
        "        SELECT sales_key FROM staging_fact_sales_incremental\n",
        "        GROUP BY sales_key\n",
        "        HAVING COUNT(*) > 1\n",
        "    )\n",
        "    \"\"\").fetchone()[0]\n",
        "\n",
        "    if dup_count > 0:\n",
        "        print(f\"PERINGATAN: Ditemukan {dup_count} kunci duplikat dalam staging. Transaksi tidak akan dimasukkan.\")\n",
        "        return\n",
        "\n",
        "    # Verifikasi bahwa kunci sales_key di staging tidak ada di fact_sales\n",
        "    overlap_keys = conn.execute(\"\"\"\n",
        "    SELECT COUNT(*) FROM staging_fact_sales_incremental s\n",
        "    WHERE s.sales_key IN (SELECT sales_key FROM fact_sales)\n",
        "    \"\"\").fetchone()[0]\n",
        "\n",
        "    if overlap_keys > 0:\n",
        "        print(f\"PERINGATAN: Ditemukan {overlap_keys} sales_key yang tumpang tindih. Transaksi tidak akan dimasukkan.\")\n",
        "        return\n",
        "\n",
        "    # Verifikasi bahwa transaction_id di staging tidak ada di fact_sales\n",
        "    overlap_transactions = conn.execute(\"\"\"\n",
        "    SELECT COUNT(*) FROM staging_fact_sales_incremental s\n",
        "    WHERE s.transaction_id IN (SELECT transaction_id FROM fact_sales)\n",
        "    \"\"\").fetchone()[0]\n",
        "\n",
        "    if overlap_transactions > 0:\n",
        "        print(f\"PERINGATAN: Ditemukan {overlap_transactions} transaction_id yang tumpang tindih. Transaksi tidak akan dimasukkan.\")\n",
        "        return\n",
        "\n",
        "    # 3. Load data baru - gunakan INSERT tanpa JOIN kompleks untuk mengurangi risiko\n",
        "    conn.execute(\"\"\"\n",
        "    INSERT INTO fact_sales (\n",
        "        sales_key, transaction_id, date_key, product_key, store_key,\n",
        "        customer_key, quantity, unit_price, unit_cost, discount_pct,\n",
        "        discount_amount, sales_amount, profit_amount\n",
        "    )\n",
        "    SELECT\n",
        "        f.sales_key, f.transaction_id, f.date_key,\n",
        "        f.product_key, f.store_key, f.customer_key,\n",
        "        f.quantity, f.unit_price, f.unit_cost,\n",
        "        f.discount_pct, f.discount_amount, f.sales_amount, f.profit_amount\n",
        "    FROM staging_fact_sales_incremental f\n",
        "    \"\"\")\n",
        "\n",
        "    # Dapatkan jumlah total rekaman setelah proses inkremental\n",
        "    inserted_count = conn.execute(\"SELECT COUNT(*) FROM staging_fact_sales_incremental\").fetchone()[0]\n",
        "    total_count = conn.execute(\"SELECT COUNT(*) FROM fact_sales\").fetchone()[0]\n",
        "    print(f\"Berhasil menambahkan {inserted_count} transaksi baru\")\n",
        "    print(f\"Total transaksi dalam data warehouse setelah proses inkremental: {total_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAzpsa05rCsd"
      },
      "source": [
        "Jalankan ETL inkremental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tSaLRIarCsd"
      },
      "outputs": [],
      "source": [
        "incremental_etl()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz-MuT8RrCse"
      },
      "source": [
        "## 10. Class ETLPipeline untuk Mengotomatisasi Semua Proses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNEHgwZorCse"
      },
      "outputs": [],
      "source": [
        "class ETLPipeline:\n",
        "    \"\"\"Class untuk mengotomatisasi proses ETL\"\"\"\n",
        "\n",
        "    def __init__(self, db_path='retail_dw.db'):\n",
        "        \"\"\"Inisialisasi pipeline\"\"\"\n",
        "        self.conn = duckdb.connect(db_path)\n",
        "        self.initialized = False\n",
        "        self.log_table_setup()\n",
        "\n",
        "    def log_table_setup(self):\n",
        "        \"\"\"Membuat tabel log untuk melacak proses ETL\"\"\"\n",
        "        self.conn.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS etl_log (\n",
        "            log_id INTEGER PRIMARY KEY,\n",
        "            process_name VARCHAR,\n",
        "            start_time TIMESTAMP,\n",
        "            end_time TIMESTAMP,\n",
        "            records_processed INTEGER,\n",
        "            status VARCHAR,\n",
        "            message VARCHAR\n",
        "        )\n",
        "        \"\"\")\n",
        "\n",
        "    def log_process_start(self, process_name):\n",
        "        \"\"\"Mencatat mulainya proses ETL\"\"\"\n",
        "        log_id = self.conn.execute(\"SELECT COALESCE(MAX(log_id), 0) + 1 FROM etl_log\").fetchone()[0]\n",
        "        self.conn.execute(\"\"\"\n",
        "        INSERT INTO etl_log (log_id, process_name, start_time, status)\n",
        "        VALUES (?, ?, CURRENT_TIMESTAMP, 'RUNNING')\n",
        "        \"\"\", [log_id, process_name])\n",
        "        return log_id\n",
        "\n",
        "    def log_process_end(self, log_id, records=0, status='SUCCESS', message=None):\n",
        "        \"\"\"Mencatat selesainya proses ETL\"\"\"\n",
        "        self.conn.execute(\"\"\"\n",
        "        UPDATE etl_log\n",
        "        SET end_time = CURRENT_TIMESTAMP,\n",
        "            records_processed = ?,\n",
        "            status = ?,\n",
        "            message = ?\n",
        "        WHERE log_id = ?\n",
        "        \"\"\", [records, status, message, log_id])\n",
        "\n",
        "    def initialize_warehouse(self):\n",
        "        \"\"\"Inisialisasi skema data warehouse jika belum ada\"\"\"\n",
        "        if self.initialized:\n",
        "            return\n",
        "\n",
        "        log_id = self.log_process_start(\"initialize_warehouse\")\n",
        "\n",
        "        try:\n",
        "            # Dimensi tanggal\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS dim_date (\n",
        "              date_key INTEGER PRIMARY KEY,\n",
        "              date DATE NOT NULL,\n",
        "              day INTEGER,\n",
        "              day_of_week INTEGER,\n",
        "              day_name VARCHAR,\n",
        "              month INTEGER,\n",
        "              month_name VARCHAR,\n",
        "              quarter INTEGER,\n",
        "              year INTEGER,\n",
        "              season VARCHAR\n",
        "            )\n",
        "            \"\"\")\n",
        "\n",
        "            # Dimensi produk\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS dim_product (\n",
        "              product_key INTEGER PRIMARY KEY,\n",
        "              product_id INTEGER NOT NULL,\n",
        "              product_name VARCHAR,\n",
        "              category VARCHAR,\n",
        "              subcategory VARCHAR,\n",
        "              unit_cost DECIMAL(10,2),\n",
        "              unit_price DECIMAL(10,2),\n",
        "              effective_date DATE,\n",
        "              expiration_date DATE,\n",
        "              current_flag BOOLEAN\n",
        "            )\n",
        "            \"\"\")\n",
        "\n",
        "            # Dimensi toko\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS dim_store (\n",
        "              store_key INTEGER PRIMARY KEY,\n",
        "              store_id INTEGER NOT NULL,\n",
        "              store_name VARCHAR,\n",
        "              city VARCHAR,\n",
        "              region VARCHAR,\n",
        "              store_type VARCHAR,\n",
        "              effective_date DATE,\n",
        "              expiration_date DATE,\n",
        "              current_flag BOOLEAN\n",
        "            )\n",
        "            \"\"\")\n",
        "\n",
        "            # Dimensi pelanggan\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS dim_customer (\n",
        "              customer_key INTEGER PRIMARY KEY,\n",
        "              customer_id INTEGER NOT NULL,\n",
        "              first_name VARCHAR,\n",
        "              last_name VARCHAR,\n",
        "              email VARCHAR,\n",
        "              city VARCHAR,\n",
        "              membership VARCHAR,\n",
        "              effective_date DATE,\n",
        "              expiration_date DATE,\n",
        "              current_flag BOOLEAN\n",
        "            )\n",
        "            \"\"\")\n",
        "\n",
        "            # Tabel fakta penjualan\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS fact_sales (\n",
        "              sales_key INTEGER PRIMARY KEY,\n",
        "              transaction_id VARCHAR,\n",
        "              date_key INTEGER,\n",
        "              product_key INTEGER,\n",
        "              store_key INTEGER,\n",
        "              customer_key INTEGER,\n",
        "              quantity INTEGER,\n",
        "              unit_price DECIMAL(10,2),\n",
        "              unit_cost DECIMAL(10,2),\n",
        "              discount_pct DECIMAL(5,2),\n",
        "              discount_amount DECIMAL(10,2),\n",
        "              sales_amount DECIMAL(10,2),\n",
        "              profit_amount DECIMAL(10,2),\n",
        "\n",
        "              FOREIGN KEY (date_key) REFERENCES dim_date(date_key),\n",
        "              FOREIGN KEY (product_key) REFERENCES dim_product(product_key),\n",
        "              FOREIGN KEY (store_key) REFERENCES dim_store(store_key),\n",
        "              FOREIGN KEY (customer_key) REFERENCES dim_customer(customer_key)\n",
        "            )\n",
        "            \"\"\")\n",
        "\n",
        "            # Berhasil inisialisasi\n",
        "            self.initialized = True\n",
        "            self.log_process_end(log_id, status='SUCCESS', message='Data warehouse schema initialized')\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_process_end(log_id, status='ERROR', message=str(e))\n",
        "            raise\n",
        "\n",
        "    def extract_all_sources(self):\n",
        "        \"\"\"Ekstrak data dari semua sumber\"\"\"\n",
        "        log_id = self.log_process_start(\"extract_all_sources\")\n",
        "\n",
        "        try:\n",
        "            # Bersihkan tabel staging\n",
        "            self.conn.execute(\"DROP TABLE IF EXISTS staging_products\")\n",
        "            self.conn.execute(\"DROP TABLE IF EXISTS staging_stores\")\n",
        "            self.conn.execute(\"DROP TABLE IF EXISTS staging_customers\")\n",
        "            self.conn.execute(\"DROP TABLE IF EXISTS staging_transactions\")\n",
        "\n",
        "            # Ekstrak data dari file CSV\n",
        "            self.conn.execute(\"CREATE TABLE staging_products AS SELECT * FROM read_csv_auto('data/products.csv')\")\n",
        "            self.conn.execute(\"CREATE TABLE staging_stores AS SELECT * FROM read_csv_auto('data/stores.csv')\")\n",
        "            self.conn.execute(\"CREATE TABLE staging_customers AS SELECT * FROM read_csv_auto('data/customers_dirty.csv')\")\n",
        "            self.conn.execute(\"CREATE TABLE staging_transactions AS SELECT * FROM read_csv_auto('data/transactions.csv')\")\n",
        "\n",
        "            # Hitung total jumlah catatan\n",
        "            total_records = 0\n",
        "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM staging_products\").fetchone()[0]\n",
        "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM staging_stores\").fetchone()[0]\n",
        "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM staging_customers\").fetchone()[0]\n",
        "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM staging_transactions\").fetchone()[0]\n",
        "\n",
        "            self.log_process_end(log_id, records=total_records, status='SUCCESS')\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_process_end(log_id, status='ERROR', message=str(e))\n",
        "            raise\n",
        "\n",
        "    def transform_data(self):\n",
        "        \"\"\"Transformasi data dari tabel staging\"\"\"\n",
        "        log_id = self.log_process_start(\"transform_data\")\n",
        "\n",
        "        try:\n",
        "            # 1. Transformasi dimensi tanggal\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE OR REPLACE TABLE dim_date AS\n",
        "            WITH date_range AS (\n",
        "              SELECT date::DATE as date\n",
        "              FROM generate_series('2022-01-01'::DATE, '2024-12-31'::DATE, INTERVAL '1 day') as date\n",
        "            )\n",
        "            SELECT\n",
        "              TO_VARCHAR(date, 'YYYYMMDD')::INTEGER AS date_key,\n",
        "              date,\n",
        "              EXTRACT(DAY FROM date) AS day,\n",
        "              EXTRACT(DOW FROM date) AS day_of_week,\n",
        "              dayname(date) AS day_name,\n",
        "              EXTRACT(MONTH FROM date) AS month,\n",
        "              monthname(date) AS month_name,\n",
        "              EXTRACT(QUARTER FROM date) AS quarter,\n",
        "              EXTRACT(YEAR FROM date) AS year,\n",
        "              CASE\n",
        "                WHEN EXTRACT(MONTH FROM date) BETWEEN 3 AND 5 THEN 'Spring'\n",
        "                WHEN EXTRACT(MONTH FROM date) BETWEEN 6 AND 8 THEN 'Summer'\n",
        "                WHEN EXTRACT(MONTH FROM date) BETWEEN 9 AND 11 THEN 'Fall'\n",
        "                ELSE 'Winter'\n",
        "              END AS season\n",
        "            FROM date_range\n",
        "            \"\"\")\n",
        "\n",
        "            # 2. Transformasi dimensi produk\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE OR REPLACE TABLE staging_dim_product AS\n",
        "            SELECT\n",
        "                product_id AS product_key,\n",
        "                product_id,\n",
        "                name AS product_name,\n",
        "                category,\n",
        "                subcategory,\n",
        "                base_cost AS unit_cost,\n",
        "                base_price AS unit_price,\n",
        "                '2022-01-01'::DATE AS effective_date,\n",
        "                NULL::DATE AS expiration_date,\n",
        "                TRUE AS current_flag\n",
        "            FROM staging_products\n",
        "            \"\"\")\n",
        "\n",
        "            # 3. Transformasi dimensi toko\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE OR REPLACE TABLE staging_dim_store AS\n",
        "            SELECT\n",
        "                store_id AS store_key,\n",
        "                store_id,\n",
        "                name AS store_name,\n",
        "                city,\n",
        "                region,\n",
        "                type AS store_type,\n",
        "                '2022-01-01'::DATE AS effective_date,\n",
        "                NULL::DATE AS expiration_date,\n",
        "                TRUE AS current_flag\n",
        "            FROM staging_stores\n",
        "            \"\"\")\n",
        "\n",
        "            # 4. Transformasi dimensi pelanggan dengan pembersihan data\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE OR REPLACE TABLE staging_dim_customer AS\n",
        "            WITH clean_customers AS (\n",
        "                SELECT\n",
        "                    customer_id,\n",
        "                    COALESCE(first_name, 'Unknown') AS first_name,\n",
        "                    COALESCE(last_name, 'Unknown') AS last_name,\n",
        "                    COALESCE(email, 'unknown@example.com') AS email,\n",
        "                    CASE\n",
        "                        WHEN city IS NULL THEN 'Unknown'\n",
        "                        ELSE INITCAP(LOWER(city)) -- Standarisasi kapitalisasi\n",
        "                    END AS city,\n",
        "                    membership,\n",
        "                    -- Ambil hanya baris pertama untuk email duplikat\n",
        "                    ROW_NUMBER() OVER (PARTITION BY email ORDER BY customer_id) AS rn\n",
        "                FROM staging_customers\n",
        "            )\n",
        "            SELECT\n",
        "                ROW_NUMBER() OVER (ORDER BY customer_id) AS customer_key,\n",
        "                customer_id,\n",
        "                first_name,\n",
        "                last_name,\n",
        "                email,\n",
        "                city,\n",
        "                membership,\n",
        "                '2022-01-01'::DATE AS effective_date,\n",
        "                NULL::DATE AS expiration_date,\n",
        "                TRUE AS current_flag\n",
        "            FROM clean_customers\n",
        "            WHERE rn = 1 -- Eliminasi duplikat\n",
        "            \"\"\")\n",
        "\n",
        "            # 5. Transformasi fakta penjualan\n",
        "            self.conn.execute(\"\"\"\n",
        "            CREATE OR REPLACE TABLE staging_fact_sales AS\n",
        "            SELECT\n",
        "                ROW_NUMBER() OVER (ORDER BY transaction_id, product_id) AS sales_key,\n",
        "                transaction_id,\n",
        "                TO_VARCHAR(DATE(date), 'YYYYMMDD')::INTEGER AS date_key,\n",
        "                product_id AS product_key, -- Akan diganti nanti dengan JOIN\n",
        "                store_id AS store_key, -- Akan diganti nanti dengan JOIN\n",
        "                customer_id AS customer_key, -- Akan diganti nanti dengan JOIN\n",
        "                quantity,\n",
        "                unit_price,\n",
        "                unit_cost,\n",
        "                discount_pct,\n",
        "                discount_amount,\n",
        "                total_amount AS sales_amount,\n",
        "                profit AS profit_amount\n",
        "            FROM staging_transactions\n",
        "            \"\"\")\n",
        "\n",
        "            # Hitung jumlah catatan\n",
        "            total_records = 0\n",
        "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM dim_date\").fetchone()[0]\n",
        "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM staging_dim_product\").fetchone()[0]\n",
        "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM staging_dim_store\").fetchone()[0]\n",
        "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM staging_dim_customer\").fetchone()[0]\n",
        "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM staging_fact_sales\").fetchone()[0]\n",
        "\n",
        "            self.log_process_end(log_id, records=total_records, status='SUCCESS')\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_process_end(log_id, status='ERROR', message=str(e))\n",
        "            raise\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load data ke data warehouse\"\"\"\n",
        "        log_id = self.log_process_start(\"load_data\")\n",
        "\n",
        "        try:\n",
        "            # 1. Muat dimensi produk\n",
        "            self.conn.execute(\"DELETE FROM dim_product\")  # Bersihkan tabel sasaran\n",
        "            self.conn.execute(\"INSERT INTO dim_product SELECT * FROM staging_dim_product\")\n",
        "\n",
        "            # 2. Muat dimensi toko\n",
        "            self.conn.execute(\"DELETE FROM dim_store\")  # Bersihkan tabel sasaran\n",
        "            self.conn.execute(\"INSERT INTO dim_store SELECT * FROM staging_dim_store\")\n",
        "\n",
        "            # 3. Muat dimensi pelanggan\n",
        "            self.conn.execute(\"DELETE FROM dim_customer\")  # Bersihkan tabel sasaran\n",
        "            self.conn.execute(\"INSERT INTO dim_customer SELECT * FROM staging_dim_customer\")\n",
        "\n",
        "            # 4. Muat fakta penjualan dengan pemetaan kunci yang benar\n",
        "            self.conn.execute(\"DELETE FROM fact_sales\")  # Bersihkan tabel sasaran\n",
        "            self.conn.execute(\"\"\"\n",
        "            INSERT INTO fact_sales\n",
        "            SELECT\n",
        "                f.sales_key,\n",
        "                f.transaction_id,\n",
        "                f.date_key,\n",
        "                p.product_key,\n",
        "                s.store_key,\n",
        "                c.customer_key,\n",
        "                f.quantity,\n",
        "                f.unit_price,\n",
        "                f.unit_cost,\n",
        "                f.discount_pct,\n",
        "                f.discount_amount,\n",
        "                f.sales_amount,\n",
        "                f.profit_amount\n",
        "            FROM staging_fact_sales f\n",
        "            JOIN dim_product p ON f.product_key = p.product_id\n",
        "            JOIN dim_store s ON f.store_key = s.store_id\n",
        "            JOIN dim_customer c ON f.customer_key = c.customer_id\n",
        "            \"\"\")\n",
        "\n",
        "            # Menghitung jumlah baris yang dimuat\n",
        "            product_count = self.conn.execute(\"SELECT COUNT(*) FROM dim_product\").fetchone()[0]\n",
        "            store_count = self.conn.execute(\"SELECT COUNT(*) FROM dim_store\").fetchone()[0]\n",
        "            customer_count = self.conn.execute(\"SELECT COUNT(*) FROM dim_customer\").fetchone()[0]\n",
        "            sales_count = self.conn.execute(\"SELECT COUNT(*) FROM fact_sales\").fetchone()[0]\n",
        "\n",
        "            total_records = product_count + store_count + customer_count + sales_count\n",
        "\n",
        "            self.log_process_end(log_id, records=total_records, status='SUCCESS',\n",
        "                                message=f'Loaded {product_count} products, {store_count} stores, '\n",
        "                                        f'{customer_count} customers, {sales_count} sales')\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.log_process_end(log_id, status='ERROR', message=str(e))\n",
        "            raise\n",
        "\n",
        "    def run_full_pipeline(self):\n",
        "        \"\"\"Jalankan seluruh pipeline ETL\"\"\"\n",
        "        print(\"Menjalankan ETL Pipeline lengkap...\")\n",
        "\n",
        "        start_time = datetime.now()\n",
        "\n",
        "        try:\n",
        "            # 1. Inisialisasi warehouse\n",
        "            self.initialize_warehouse()\n",
        "            print(\"âœ“ Data warehouse diinisialisasi\")\n",
        "\n",
        "            # 2. Ekstrak data\n",
        "            self.extract_all_sources()\n",
        "            print(\"âœ“ Data diekstrak dari semua sumber\")\n",
        "\n",
        "            # 3. Transform data\n",
        "            self.transform_data()\n",
        "            print(\"âœ“ Data ditransformasi\")\n",
        "\n",
        "            # 4. Load data\n",
        "            self.load_data()\n",
        "            print(\"âœ“ Data dimuat ke data warehouse\")\n",
        "\n",
        "            end_time = datetime.now()\n",
        "            duration = (end_time - start_time).total_seconds()\n",
        "\n",
        "            print(f\"\\nPipeline ETL selesai dalam {duration:.2f} detik\")\n",
        "\n",
        "            # Menampilkan statistik\n",
        "            stats = self.conn.execute(\"\"\"\n",
        "                SELECT\n",
        "                    (SELECT COUNT(*) FROM dim_date) as date_count,\n",
        "                    (SELECT COUNT(*) FROM dim_product) as product_count,\n",
        "                    (SELECT COUNT(*) FROM dim_store) as store_count,\n",
        "                    (SELECT COUNT(*) FROM dim_customer) as customer_count,\n",
        "                    (SELECT COUNT(*) FROM fact_sales) as sales_count\n",
        "            \"\"\").fetchone()\n",
        "\n",
        "            print(\"\\nStatistik Data Warehouse:\")\n",
        "            print(f\"âœ“ Dimensi Tanggal: {stats[0]} baris\")\n",
        "            print(f\"âœ“ Dimensi Produk: {stats[1]} baris\")\n",
        "            print(f\"âœ“ Dimensi Toko: {stats[2]} baris\")\n",
        "            print(f\"âœ“ Dimensi Pelanggan: {stats[3]} baris\")\n",
        "            print(f\"âœ“ Fakta Penjualan: {stats[4]} baris\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR: Pipeline ETL gagal: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def get_etl_log(self, limit=10):\n",
        "        \"\"\"Menampilkan log ETL terakhir\"\"\"\n",
        "        return self.conn.execute(f\"\"\"\n",
        "            SELECT\n",
        "                log_id,\n",
        "                process_name,\n",
        "                start_time,\n",
        "                end_time,\n",
        "                EXTRACT(EPOCH FROM (end_time - start_time)) as duration_seconds,\n",
        "                records_processed,\n",
        "                status,\n",
        "                message\n",
        "            FROM etl_log\n",
        "            ORDER BY log_id DESC\n",
        "            LIMIT {limit}\n",
        "        \"\"\").fetchdf()\n",
        "\n",
        "    def __del__(self):\n",
        "        \"\"\"Menutup koneksi saat objek dihapus\"\"\"\n",
        "        try:\n",
        "            if hasattr(self, 'conn'):\n",
        "                self.conn.close()\n",
        "                print(\"Koneksi DuckDB ditutup.\")\n",
        "        except:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Csb8ob1arCsf"
      },
      "source": [
        "Jalankan pipeline otomatis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqxMlng3rCsf"
      },
      "outputs": [],
      "source": [
        "pipeline = ETLPipeline()\n",
        "pipeline.run_full_pipeline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK-l1dfWrCsf"
      },
      "source": [
        "Lihat log ETL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4pf9v6trCsf"
      },
      "outputs": [],
      "source": [
        "pipeline.get_etl_log()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPIutrbPrCsf"
      },
      "source": [
        "## 11. Kesimpulan\n",
        "\n",
        "Dalam tutorial ini, kita telah mempelajari:\n",
        "\n",
        "1. **Konsep dasar data warehouse** - OLTP vs OLAP, desain dimensional\n",
        "2. **Implementasi Schema** - Star Schema, Snowflake Schema, dan Fact Constellation\n",
        "3. **Proses ETL** - Extract, Transform, Load dengan berbagai pendekatan\n",
        "   - Transformasi menggunakan pandas (Python)\n",
        "   - Transformasi menggunakan SQL di DuckDB\n",
        "4. **SCD Type 2** - Menangani perubahan historis pada dimensi\n",
        "5. **ETL Inkremental** - Memproses hanya data baru\n",
        "6. **Otomatisasi Pipeline** - Membuat class untuk mengelola seluruh proses\n",
        "\n",
        "Beberapa _best practice_ yang telah kita terapkan:\n",
        "\n",
        "1. **Pembersihan data** - Menangani data yang hilang, duplikat, dan inkonsistensi\n",
        "2. **Pelacakan historis** - Menggunakan SCD Type 2 untuk _tracking_ perubahan\n",
        "3. **Pemisahan tanggung jawab** - Memisahkan ekstraksi, transformasi, dan loading\n",
        "4. **Logging** - Mencatat semua proses ETL\n",
        "5. **Error handling** - Menangani kesalahan dengan baik\n",
        "6. **Dokumentasi** - Menjelaskan setiap langkah proses"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}